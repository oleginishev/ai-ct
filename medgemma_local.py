#!/usr/bin/env python3
"""
–†–∞–±–æ—Ç–∞ —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é MedGemma 4B
"""

import os
from transformers import AutoProcessor, AutoModelForImageTextToText
from PIL import Image
import torch
import requests

# –ü—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
MODEL_PATH = "./models/medgemma_4b"

def load_local_medgemma():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ MedGemma"""
    print('üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å MedGemma...')
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
        processor = AutoProcessor.from_pretrained(MODEL_PATH)
        print('‚úÖ Processor –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–∏!')
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
        model = AutoModelForImageTextToText.from_pretrained(
            MODEL_PATH,
            torch_dtype=torch.bfloat16,
            device_map='auto',
            low_cpu_mem_usage=True,
            attn_implementation="flash_attention_2" if torch.cuda.is_available() else None
        )
        print('‚úÖ Model –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–∏!')
        print('üéâ –õ–æ–∫–∞–ª—å–Ω–∞—è MedGemma –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!')
        
        return model, processor
        
    except Exception as e:
        print(f'‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}')
        return None, None

def analyze_chest_xray_local(model, processor, image_path=None):
    """–ê–Ω–∞–ª–∏–∑ —Ä–µ–Ω—Ç–≥–µ–Ω–æ–≤—Å–∫–æ–≥–æ —Å–Ω–∏–º–∫–∞ —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é"""
    print('\nü´Å –ê–Ω–∞–ª–∏–∑ —Ä–µ–Ω—Ç–≥–µ–Ω–æ–≤—Å–∫–æ–≥–æ —Å–Ω–∏–º–∫–∞ (–ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å)...')
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        if image_path and os.path.exists(image_path):
            image = Image.open(image_path)
            print(f'üìÅ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}')
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image_url = "https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png"
            image = Image.open(requests.get(image_url, headers={"User-Agent": "example"}, stream=True).raw)
            print('üì∑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞')
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º
        messages = [
            {
                "role": "system",
                "content": [{"type": "text", "text": "–í—ã —ç–∫—Å–ø–µ—Ä—Ç-—Ä–µ–Ω—Ç–≥–µ–Ω–æ–ª–æ–≥. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ä–µ–Ω—Ç–≥–µ–Ω–æ–≤—Å–∫–∏–π —Å–Ω–∏–º–æ–∫ –≥—Ä—É–¥–Ω–æ–π –∫–ª–µ—Ç–∫–∏ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ –ø–æ–¥—Ä–æ–±–Ω—ã–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –æ—Ç—á–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."}]
            },
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —ç—Ç–æ—Ç —Ä–µ–Ω—Ç–≥–µ–Ω–æ–≤—Å–∫–∏–π —Å–Ω–∏–º–æ–∫ –≥—Ä—É–¥–Ω–æ–π –∫–ª–µ—Ç–∫–∏ –∏ –æ–ø–∏—à–∏—Ç–µ –ª—é–±—ã–µ –Ω–∞—Ö–æ–¥–∫–∏, –∞–Ω–æ–º–∞–ª–∏–∏ –∏–ª–∏ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –Ω–∞–±–ª—é–¥–∞–µ—Ç–µ. –û—Ç–≤–µ—á–∞–π—Ç–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."},
                    {"type": "image", "image": image}
                ]
            }
        ]
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å –ø–æ–º–æ—â—å—é –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
        print('üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...')
        inputs = processor.apply_chat_template(
            messages, add_generation_prompt=True, tokenize=True,
            return_dict=True, return_tensors="pt"
        ).to(model.device, dtype=torch.bfloat16)
        
        input_len = inputs["input_ids"].shape[-1]
        
        with torch.inference_mode():
            generation = model.generate(
                **inputs, 
                max_new_tokens=150,  # –£–º–µ–Ω—å—à–∏–ª–∏ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                do_sample=False,
                temperature=0.1,
                top_p=0.9,
                pad_token_id=processor.tokenizer.eos_token_id
            )
            generation = generation[0][input_len:]
        
        result = processor.decode(generation, skip_special_tokens=True)
        
        print('\nüìã –†–ï–ó–£–õ–¨–¢–ê–¢ –ê–ù–ê–õ–ò–ó–ê (–ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å):')
        print('=' * 60)
        print(result)
        print('=' * 60)
        
        return result
        
    except Exception as e:
        print(f'‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}')
        return None

def medical_qa_local(model, processor, question):
    """–û—Ç–≤–µ—Ç –Ω–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é"""
    print(f'\n‚ùì –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å: {question}')
    
    try:
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º
        prompt = f"""–í—ã —ç–∫—Å–ø–µ—Ä—Ç-–º–µ–¥–∏–∫. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å —Ç–æ—á–Ω–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:

–í–æ–ø—Ä–æ—Å: {question}

–û—Ç–≤–µ—Ç:"""
        
        # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º
        inputs = processor.tokenizer(prompt, return_tensors="pt").to(model.device)
        
        print('üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–æ–ø—Ä–æ—Å...')
        with torch.inference_mode():
            generation = model.generate(
                **inputs, 
                max_new_tokens=100,  # –£–º–µ–Ω—å—à–∏–ª–∏ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                do_sample=False,
                temperature=0.1,
                top_p=0.9,
                pad_token_id=processor.tokenizer.eos_token_id
            )
            generation = generation[0][inputs["input_ids"].shape[-1]:]
        
        result = processor.tokenizer.decode(generation, skip_special_tokens=True)
        
        print('\nüìã –û–¢–í–ï–¢ (–ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å):')
        print('=' * 60)
        print(result)
        print('=' * 60)
        
        return result
        
    except Exception as e:
        print(f'‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞: {e}')
        return None

def test_local_model():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    print('üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å MedGemma...')
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model, processor = load_local_medgemma()
    if model is None or processor is None:
        return False
    
    # –¢–µ—Å—Ç 1: –ê–Ω–∞–ª–∏–∑ —Ä–µ–Ω—Ç–≥–µ–Ω–æ–≤—Å–∫–æ–≥–æ —Å–Ω–∏–º–∫–∞
    print('\n' + '=' * 60)
    print('üìã –¢–ï–°–¢ 1: –ê–Ω–∞–ª–∏–∑ —Ä–µ–Ω—Ç–≥–µ–Ω–æ–≤—Å–∫–æ–≥–æ —Å–Ω–∏–º–∫–∞')
    analyze_chest_xray_local(model, processor)
    
    # –¢–µ—Å—Ç 2: –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å
    print('\n' + '=' * 60)
    print('üìã –¢–ï–°–¢ 2: –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å')
    medical_qa_local(model, processor, "–ö–∞–∫–∏–µ –æ—Å–Ω–æ–≤–Ω—ã–µ —Å–∏–º–ø—Ç–æ–º—ã –ø–Ω–µ–≤–º–æ–Ω–∏–∏?")
    
    # –¢–µ—Å—Ç 3: –ï—â–µ –æ–¥–∏–Ω –≤–æ–ø—Ä–æ—Å
    print('\n' + '=' * 60)
    print('üìã –¢–ï–°–¢ 3: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å')
    medical_qa_local(model, processor, "–ö–∞–∫ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É–µ—Ç—Å—è —Ç—É–±–µ—Ä–∫—É–ª–µ–∑?")
    
    print('\n' + '=' * 60)
    print('‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã!')
    print('üí° –õ–æ–∫–∞–ª—å–Ω–∞—è MedGemma —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ!')
    
    return True

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print('üè• MedGemma 4B - –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å')
    print('=' * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    if not os.path.exists(MODEL_PATH):
        print(f'‚ùå –õ–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ {MODEL_PATH}')
        print('üí° –°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å –∫–æ–º–∞–Ω–¥–æ–π:')
        print('huggingface-cli download google/medgemma-4b-it --local-dir models/medgemma_4b')
        return
    
    print(f'üìÅ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑: {MODEL_PATH}')
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
    success = test_local_model()
    
    if success:
        print('\nüéâ –õ–æ–∫–∞–ª—å–Ω–∞—è MedGemma –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!')
        print('üí° –¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞!')
    else:
        print('\n‚ùå –í–æ–∑–Ω–∏–∫–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª—å—é')

if __name__ == "__main__":
    main()
