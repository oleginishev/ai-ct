#!/usr/bin/env python3
"""
DICOM Analyzer Script (Simplified)
==================================

–ü—Ä–æ—Å—Ç–æ–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ DICOM —Ñ–∞–π–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º MedGemma.
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ DICOM —Ñ–∞–π–ª—ã –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ –∏ –≤—ã–≤–æ–¥–∏—Ç –æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- transformers
- torch
- pydicom
- PIL
- numpy
- tqdm (–¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞)
- datasets (–¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ GPU)
"""

import os
import sys
import glob
import time
import numpy as np
from pathlib import Path
import pydicom
from PIL import Image
import torch
from transformers import pipeline
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
import os
os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # –ò–∑–±–µ–≥–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –æ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞

# –ò–º–ø–æ—Ä—Ç –¥–ª—è Telegram –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
import requests
import json
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç datasets –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
try:
    from datasets import Dataset
    DATASETS_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'datasets' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –º–µ–Ω–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞.")
    print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install datasets")
    DATASETS_AVAILABLE = False

# ===== –ù–ê–°–¢–†–û–ô–ö–ò =====
# –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å DICOM —Ñ–∞–π–ª–∞–º–∏ (–∏–∑–º–µ–Ω–∏—Ç–µ –Ω–∞ —Å–≤–æ–π –ø—É—Ç—å)
DICOM_FOLDER_PATH = "data"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–∞–ø–∫–∞ data

# Debug —Ä–µ–∂–∏–º - –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ N –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
DEBUG_MODE = False  # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ True –¥–ª—è debug —Ä–µ–∂–∏–º–∞
DEBUG_LIMIT = 50    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤ debug —Ä–µ–∂–∏–º–µ

# ===== –ù–ê–°–¢–†–û–ô–ö–ò TELEGRAM =====
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Telegram –±–æ—Ç–∞ (–±—É–¥—É—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —á–µ—Ä–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏)
TELEGRAM_BOT_TOKEN = None
TELEGRAM_CHAT_ID = None
TELEGRAM_ENABLED = False


# –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ MedGemma
AVAILABLE_MODELS = {
    "4b": "google/medgemma-4b-it",
    "27b": "google/medgemma-27b-it"
}
DEFAULT_MODEL = "4b"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º 4B –º–æ–¥–µ–ª—å

# ===== –ù–ê–°–¢–†–û–ô–ö–ò –ê–ù–ê–õ–ò–ó–ê –°–ù–ò–ú–ö–û–í =====
# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã CT windowing –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
DEFAULT_WINDOW_LEVEL = -550   # WL (—Ü–µ–Ω—Ç—Ä –æ–∫–Ω–∞)
DEFAULT_WINDOW_WIDTH = 1600   # WW (—à–∏—Ä–∏–Ω–∞ –æ–∫–Ω–∞)

# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –æ–∫–Ω–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –≤—ã—è–≤–ª–µ–Ω–∏—è –ø–Ω–µ–≤–º–æ–Ω–∏–∏
PNEUMONIA_DETECTION_WINDOWS = {
    "lung_soft": {"wl": -400, "ww": 1400},      # –ú—è–≥–∫–æ–µ –ª–µ–≥–æ—á–Ω–æ–µ –æ–∫–Ω–æ
    "infection": {"wl": -300, "ww": 1200},      # –û–∫–Ω–æ –¥–ª—è –∏–Ω—Ñ–µ–∫—Ü–∏–π
    "standard_lung": {"wl": -600, "ww": 1600}   # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –ª–µ–≥–æ—á–Ω–æ–µ
}

# –Ø–∑—ã–∫–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤
LANGUAGE_PROMPTS = {
    "en": """You are an expert radiologist and pulmonologist with extensive experience in chest CT analysis. 

Analyze this medical image and provide a detailed assessment focusing on:
1. Lung pathology: pneumonia, consolidations, ground-glass opacities
2. Pleural changes: effusions, thickening
3. Airways: air bronchograms, bronchial wall thickening  
4. Overall lung architecture and any abnormalities
5. Clinical recommendations

Be thorough but concise. Report both normal and abnormal findings. If any concerning features are present, describe their location and characteristics in detail.""",
    
    "ru": """–í—ã - —ç–∫—Å–ø–µ—Ä—Ç-—Ä–µ–Ω—Ç–≥–µ–Ω–æ–ª–æ–≥ –∏ –ø—É–ª—å–º–æ–Ω–æ–ª–æ–≥ —Å –æ–±—à–∏—Ä–Ω—ã–º –æ–ø—ã—Ç–æ–º –∞–Ω–∞–ª–∏–∑–∞ –ö–¢ –≥—Ä—É–¥–Ω–æ–π –∫–ª–µ—Ç–∫–∏.

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —ç—Ç–æ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ –¥–µ—Ç–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É, —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏–≤—à–∏—Å—å –Ω–∞:
1. –ü–∞—Ç–æ–ª–æ–≥–∏–∏ –ª–µ–≥–∫–∏—Ö: –ø–Ω–µ–≤–º–æ–Ω–∏—è, –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏, –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ —Ç–∏–ø—É "–º–∞—Ç–æ–≤–æ–≥–æ —Å—Ç–µ–∫–ª–∞"
2. –ü–ª–µ–≤—Ä–∞–ª—å–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è: –≤—ã–ø–æ—Ç, —É—Ç–æ–ª—â–µ–Ω–∏–µ
3. –î—ã—Ö–∞—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏: –≤–æ–∑–¥—É—à–Ω—ã–µ –±—Ä–æ–Ω—Ö–æ–≥—Ä–∞–º–º—ã, —É—Ç–æ–ª—â–µ–Ω–∏–µ —Å—Ç–µ–Ω–æ–∫ –±—Ä–æ–Ω—Ö–æ–≤
4. –û–±—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ª–µ–≥–∫–∏—Ö –∏ –ª—é–±—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏
5. –ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–ë—É–¥—å—Ç–µ —Ç—â–∞—Ç–µ–ª—å–Ω—ã–º–∏, –Ω–æ –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º–∏. –°–æ–æ–±—â–∞–π—Ç–µ –∫–∞–∫ –æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö, —Ç–∞–∫ –∏ –æ –ø–∞—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –Ω–∞—Ö–æ–¥–∫–∞—Ö. –ï—Å–ª–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ç—Ä–µ–≤–æ–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –æ–ø–∏—à–∏—Ç–µ –∏—Ö –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏—é –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –ø–æ–¥—Ä–æ–±–Ω–æ."""
}

# –ï–¥–∏–Ω—ã–π —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≤—Å–µ—Ö —Å–ª—É—á–∞–µ–≤ –∞–Ω–∞–ª–∏–∑–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∞–Ω–≥–ª–∏–π—Å–∫–∏–π)
DEFAULT_ANALYSIS_PROMPT = LANGUAGE_PROMPTS["en"]
CURRENT_LANGUAGE = "en"

# ENGLISH VERSION - Normal-Focused CT Analysis Prompts
ANALYSIS_PROMPTS_EN = {
    # System prompt - defining the expert role focused on normal findings
    "system": "You are an expert pulmonologist and chest radiologist specializing in identifying normal lung anatomy and physiology. Your primary expertise is recognizing healthy lung tissue characteristics, normal density ranges (HU values), proper anatomical positioning, and intact thoracic cavity structure. You excel at distinguishing normal variations from pathological changes by first establishing what constitutes normal lung architecture.",
   
    # Prompt for single image analysis
    "single_image": "CRITICAL: Begin by systematically evaluating this chest CT scan for NORMAL lung characteristics. First assess: 1) NORMAL lung density (-950 to -500 HU for healthy lung parenchyma), 2) Appropriate lung size and expansion bilaterally, 3) Normal lung edges conforming to pleural boundaries, 4) Normal bronchial and bronchiolar diameter and wall thickness, 5) Proper mediastinal positioning (no shift), 6) Normal cardiac and great vessel size and position, 7) Intact chest wall and pleural surfaces. ONLY after confirming these normal parameters, identify any deviations: abnormal densities (consolidation +10 to +40 HU, ground-glass -500 to -100 HU, masses >+40 HU), mediastinal shift direction and cause (fluid, gas, mass effect), enlarged structures, or edge irregularities. If lungs meet normal criteria but extra-pulmonary findings exist (breast masses, abdominal findings), classify as NORMAL LUNGS with commentary on incidental findings.",
   
    # Prompt for batch analysis (concise)
    "batch_analysis": "Systematically assess this chest CT for normal lung characteristics first: appropriate density (-950 to -500 HU), proper size/expansion, normal edges within pleural boundaries, standard bronchial caliber, centered mediastinum, normal cardiac size. Then identify any deviations from these normal parameters. If lungs are normal but incidental findings present, classify as normal lungs with notes on extra-pulmonary observations.",
   
    # Prompt for series report
    "series_report": "Based on analysis of {count} chest CT images from a DICOM series, create a comprehensive pulmonary radiological report focused on NORMAL vs ABNORMAL lung classification. First establish normal baseline: lung density (-950 to -500 HU), bilateral symmetry, proper pleural conformity, normal bronchial architecture, centered mediastinum, appropriate organ sizes. Review all individual analyses for patterns:\n\n{analyses}\n\nProvide definitive assessment: Do the lungs meet normal criteria? If deviations exist, specify: density changes (HU values), structural alterations, mediastinal shift direction/cause, size abnormalities. If lungs are normal but extra-pulmonary findings noted, classify as NORMAL LUNGS with incidental findings commentary. Clinical recommendation should reflect lung status primarily.",
   
    # System prompt for series report
    "series_system": "You are an expert pulmonologist and chest radiologist specializing in normal lung anatomy recognition and systematic exclusion of pathology. Your expertise lies in establishing normal baselines first, then identifying deviations that warrant further investigation."
}

# –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ normal-focused –≤–µ—Ä—Å–∏—é
ANALYSIS_PROMPTS = {
    # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç - –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–æ–ª—å —ç–∫—Å–ø–µ—Ä—Ç–∞
    "system": ANALYSIS_PROMPTS_EN["system"],
    
    # –ï–¥–∏–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
    "universal": ANALYSIS_PROMPTS_EN["single_image"],
    
    # –ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    "single_image": ANALYSIS_PROMPTS_EN["single_image"],
    
    # –ü—Ä–æ–º–ø—Ç –¥–ª—è –±–∞—Ç—á–µ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (–∫—Ä–∞—Ç–∫–∏–π)
    "batch_analysis": ANALYSIS_PROMPTS_EN["batch_analysis"],
    
    # –ü—Ä–æ–º–ø—Ç –¥–ª—è –æ–±—â–µ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø–æ —Å–µ—Ä–∏–∏
    "series_report": ANALYSIS_PROMPTS_EN["series_report"],
    
    # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ–±—â–µ–≥–æ –æ—Ç—á–µ—Ç–∞
    "series_system": ANALYSIS_PROMPTS_EN["series_system"]
}

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
GENERATION_PARAMS = {
    "single_image_tokens": 300,    # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø–Ω–µ–≤–º–æ–Ω–∏–∏
    "batch_tokens": 200,           # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –ª—É—á—à–µ–≥–æ –≤—ã—è–≤–ª–µ–Ω–∏—è –ø–∞—Ç–æ–ª–æ–≥–∏–π
    "series_report_tokens": 500    # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
}

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
IMAGE_PROCESSING = {
    "convert_to_hu": True,         # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ Hounsfield Units
    "apply_windowing": True,       # –ü—Ä–∏–º–µ–Ω—è—Ç—å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–µ –æ–∫–Ω–æ
    "default_modality": "CT",      # –ú–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    "fallback_normalization": True # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å min-max –µ—Å–ª–∏ –Ω–µ CT
}

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
PERFORMANCE_SETTINGS = {
    "batch_size_cuda": 4,           # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è CUDA GPU (—É–º–µ–Ω—å—à–µ–Ω –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)
    "batch_size_cpu": 1,            # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è CPU
    "progress_update_interval": 5,  # –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ N –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    "large_dataset_threshold": 50,  # –ü–æ—Ä–æ–≥ –¥–ª—è "–±–æ–ª—å—à–æ–≥–æ" –¥–∞—Ç–∞—Å–µ—Ç–∞
    "memory_safety_margin": 0.8     # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø–∞–º—è—Ç–∏ (80%)
}

class TelegramNotifier:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –≤ Telegram"""
    
    def __init__(self, bot_token, chat_id):
        self.bot_token = bot_token
        self.chat_id = chat_id
        self.enabled = bot_token is not None and chat_id is not None
        
        if self.enabled:
            print(f"üì± Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤–∫–ª—é—á–µ–Ω—ã (Chat ID: {chat_id})")
        
    def send_message(self, message, parse_mode='Markdown'):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram"""
        if not self.enabled:
            return False
            
        try:
            url = f"https://api.telegram.org/bot{self.bot_token}/sendMessage"
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–∞ —á–∞—Å—Ç–∏ (Telegram –ª–∏–º–∏—Ç ~4096 —Å–∏–º–≤–æ–ª–æ–≤)
            max_length = 4000
            if len(message) > max_length:
                parts = [message[i:i+max_length] for i in range(0, len(message), max_length)]
                for i, part in enumerate(parts):
                    if i > 0:
                        part = f"...(–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ {i+1}/{len(parts)})\n\n" + part
                    self._send_single_message(part, parse_mode)
            else:
                return self._send_single_message(message, parse_mode)
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {e}")
            return False
    
    def _send_single_message(self, message, parse_mode):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        try:
            url = f"https://api.telegram.org/bot{self.bot_token}/sendMessage"
            data = {
                'chat_id': self.chat_id,
                'text': message,
                'parse_mode': parse_mode
            }
            
            response = requests.post(url, data=data, timeout=10)
            return response.status_code == 200
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
            return False
    
    def send_status(self, status, details=""):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å—Ç–∞—Ç—É—Å–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        status_icons = {
            "start": "üöÄ",
            "analysis_start": "üî¨", 
            "analysis_complete": "‚úÖ",
            "report": "üìä",
            "error": "‚ùå"
        }
        
        # –¢–µ–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ —á–∞—Ç–µ
        status_tags = {
            "start": "#DICOM_START #AI_CT #ANALYSIS_STARTED",
            "analysis_start": "#DICOM_PROCESSING #AI_CT #ANALYSIS_PHASE", 
            "analysis_complete": "#DICOM_COMPLETE #AI_CT #ANALYSIS_FINISHED",
            "report": "#DICOM_REPORT #AI_CT #MEDICAL_REPORT #RESULTS",
            "error": "#DICOM_ERROR #AI_CT #ERROR_LOG"
        }
        
        icon = status_icons.get(status, "‚ÑπÔ∏è")
        tags = status_tags.get(status, "#AI_CT #DICOM")
        
        if status == "start":
            message = f"{icon} *DICOM Analysis Started*\n‚è∞ {timestamp}\n{details}\n\n{tags}"
        elif status == "analysis_start":
            message = f"{icon} *Analysis Phase Started*\n‚è∞ {timestamp}\n{details}\n\n{tags}"
        elif status == "analysis_complete":
            message = f"{icon} *Analysis Phase Completed*\n‚è∞ {timestamp}\n{details}\n\n{tags}"
        elif status == "report":
            message = f"{icon} *Final Report*\n‚è∞ {timestamp}\n\n{details}\n\n{tags}"
        elif status == "error":
            message = f"{icon} *Error Occurred*\n‚è∞ {timestamp}\n{details}\n\n{tags}"
        else:
            message = f"{icon} *Status Update*\n‚è∞ {timestamp}\n{details}\n\n{tags}"
            
        return self.send_message(message)

class DICOMAnalyzer:
    """–ö–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ DICOM —Ñ–∞–π–ª–æ–≤ —Å –ø–æ–º–æ—â—å—é MedGemma"""
    
    def __init__(self, model_name="4b", window_level=DEFAULT_WINDOW_LEVEL, window_width=DEFAULT_WINDOW_WIDTH, batch_size=None, telegram_notifier=None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        
        # Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
        self.telegram = telegram_notifier
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã windowing
        self.window_level = window_level
        self.window_width = window_width
        print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã CT –æ–∫–Ω–∞: WL={self.window_level}, WW={self.window_width}")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π GPU –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if batch_size is not None:
            self.batch_size = batch_size
            print(f"üîß –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {self.batch_size}")
        else:
            self.batch_size = PERFORMANCE_SETTINGS["batch_size_cuda"] if self.device == "cuda" else PERFORMANCE_SETTINGS["batch_size_cpu"]
            print(f"‚öôÔ∏è  –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {self.batch_size}")
        
        # –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø–æ–∫–∞–∑–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        self.progress_interval = PERFORMANCE_SETTINGS["progress_update_interval"]
        
        # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
        if model_name not in AVAILABLE_MODELS:
            print(f"‚ùå –û–®–ò–ë–ö–ê: –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å '{model_name}'")
            print(f"üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {list(AVAILABLE_MODELS.keys())}")
            print(f"üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: --model=4b –∏–ª–∏ --model=27b")
            raise ValueError(f"–ú–æ–¥–µ–ª—å '{model_name}' –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. –î–æ—Å—Ç—É–ø–Ω—ã: {list(AVAILABLE_MODELS.keys())}")
        
        self.model_name = model_name
        self.model_path = AVAILABLE_MODELS[model_name]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ MedGemma –º–æ–¥–µ–ª—å
        if "medgemma" not in self.model_path.lower():
            raise ValueError(f"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏ MedGemma. –ü–æ–ª—É—á–µ–Ω–∞: {self.model_path}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MedGemma pipeline
        print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º MedGemma –º–æ–¥–µ–ª—å: {self.model_path}")
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º MedGemma —Å –±–∞–∑–æ–≤—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
            self.pipe = pipeline(
                "image-text-to-text",
                model=self.model_path,
                torch_dtype=torch.bfloat16 if self.device == "cuda" else torch.float32,
                device=self.device,
                trust_remote_code=True,
                use_fast=False,
                batch_size=self.batch_size if self.device == "cuda" else 1  # –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è GPU
            )
        except Exception as e:
            print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å {self.model_path}")
            print(f"–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {e}")
            print("\nüîß –í–û–ó–ú–û–ñ–ù–´–ï –†–ï–®–ï–ù–ò–Ø:")
            print("1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω Hugging Face: export HF_TOKEN='your_token'")
            print("2. –ó–∞–ø—Ä–æ—Å–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ –º–æ–¥–µ–ª–∏: https://huggingface.co/google/medgemma-4b-it")
            print("3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ")
            print("4. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install -r requirements_dicom_analyzer.txt")
            
            # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏ –¢–û–õ–¨–ö–û –¥–ª—è MedGemma
            print("\nüîÑ –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏ MedGemma...")
            
            try:
                from transformers import AutoTokenizer, AutoModelForCausalLM
                
                tokenizer = AutoTokenizer.from_pretrained(
                    self.model_path, 
                    trust_remote_code=True
                )
                model = AutoModelForCausalLM.from_pretrained(
                    self.model_path, 
                    torch_dtype=torch.bfloat16 if self.device == "cuda" else torch.float32,
                    device_map="auto" if self.device == "cuda" else None,
                    trust_remote_code=True
                )
                
                self.pipe = pipeline(
                    "text-generation",
                    model=model,
                    tokenizer=tokenizer,
                    device=self.device
                )
                print("‚úÖ MedGemma –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —á–µ—Ä–µ–∑ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥")
                
            except Exception as e2:
                print(f"‚ùå –§–ê–¢–ê–õ–¨–ù–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å MedGemma –º–æ–¥–µ–ª—å")
                print(f"–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –æ—à–∏–±–∫–∞: {e2}")
                print("\nüíÄ –ê–ù–ê–õ–ò–ó –û–°–¢–ê–ù–û–í–õ–ï–ù. –ò—Å–ø—Ä–∞–≤—å—Ç–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –º–æ–¥–µ–ª—å—é –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ –∑–∞–ø—É—Å–∫.")
                print("üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: https://huggingface.co/google/medgemma-4b-it")
                raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å {self.model_path}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω –¥–æ—Å—Ç—É–ø–∞ –∏ –ø—Ä–∞–≤–∞.")
        print(f"MedGemma {model_name.upper()} –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print("–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ 'pipelines sequentially on GPU' - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞—Ç—á–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.")
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        self.results = []
        
    def apply_ct_windowing(self, image_array, window_center=40, window_width=400):
        """
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–∫–Ω–∞ –¥–ª—è CT –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –≤ —Ä–∞–¥–∏–æ–ª–æ–≥–∏–∏)
        
        Args:
            image_array (numpy.ndarray): –ò—Å—Ö–æ–¥–Ω—ã–π –º–∞—Å—Å–∏–≤ –ø–∏–∫—Å–µ–ª–µ–π –≤ HU
            window_center (int): –¶–µ–Ω—Ç—Ä –æ–∫–Ω–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 40 HU –¥–ª—è –º—è–≥–∫–∏—Ö —Ç–∫–∞–Ω–µ–π)
            window_width (int): –®–∏—Ä–∏–Ω–∞ –æ–∫–Ω–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 400 HU)
            
        Returns:
            numpy.ndarray: –ú–∞—Å—Å–∏–≤ –ø–∏–∫—Å–µ–ª–µ–π 0-255
        """
        min_hu = window_center - window_width // 2
        max_hu = window_center + window_width // 2
        
        # –û–±—Ä–µ–∑–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ –æ–∫–Ω—É
        windowed = np.clip(image_array, min_hu, max_hu)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É 0-255
        if max_hu > min_hu:
            windowed = ((windowed - min_hu) / (max_hu - min_hu) * 255).astype(np.uint8)
        else:
            windowed = np.zeros_like(windowed, dtype=np.uint8)
        
        return windowed
    
    def load_dicom_as_image(self, dicom_path, silent=False):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ DICOM —Ñ–∞–π–ª–∞ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ PIL Image —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º CT windowing
        
        Args:
            dicom_path (str): –ü—É—Ç—å –∫ DICOM —Ñ–∞–π–ª—É
            silent (bool): –ù–µ –≤—ã–≤–æ–¥–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö (–¥–ª—è –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏)
            
        Returns:
            PIL.Image: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ DICOM —Ñ–∞–π–ª–∞
            dicom = pydicom.dcmread(dicom_path)
            image_array = dicom.pixel_array.astype(np.float32)
            
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ Rescale Slope –∏ Intercept (–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ HU –µ–¥–∏–Ω–∏—Ü—ã)
            if hasattr(dicom, 'RescaleSlope') and hasattr(dicom, 'RescaleIntercept'):
                slope = float(dicom.RescaleSlope)
                intercept = float(dicom.RescaleIntercept)
                image_array = image_array * slope + intercept
                if not silent:
                    print(f"–ü—Ä–∏–º–µ–Ω–µ–Ω—ã DICOM –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: Slope={slope}, Intercept={intercept}")
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –¥–ª—è –≤—ã–±–æ—Ä–∞ –æ–∫–Ω–∞
            modality = getattr(dicom, 'Modality', 'CT')
            body_part = getattr(dicom, 'BodyPartExamined', '').upper()
            
            # –í—ã–±–æ—Ä –æ–∫–Ω–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
            if modality == 'CT':
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
                window_center, window_width = self.window_level, self.window_width
                if not silent:
                    print(f"–ü—Ä–∏–º–µ–Ω–µ–Ω–æ CT –æ–∫–Ω–æ: WL={window_center}, WW={window_width}")
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö —á–∞—Å—Ç–µ–π —Ç–µ–ª–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                if 'BRAIN' in body_part or 'HEAD' in body_part:
                    # –ú–æ–∑–≥–æ–≤–æ–µ –æ–∫–Ω–æ (–º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
                    # window_center, window_width = 40, 80
                    # print(f"–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –º–æ–∑–≥–æ–≤–æ–µ –æ–∫–Ω–æ: WL={window_center}, WW={window_width}")
                    pass
                elif 'BONE' in body_part:
                    # –ö–æ—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ (–º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)  
                    # window_center, window_width = 400, 1800
                    # print(f"–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –∫–æ—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ: WL={window_center}, WW={window_width}")
                    pass
                
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–∏–º–µ–Ω—è–µ–º–æ–º –æ–∫–Ω–µ
                min_hu = window_center - window_width // 2
                max_hu = window_center + window_width // 2
                if not silent:
                    print(f"–î–∏–∞–ø–∞–∑–æ–Ω HU: {min_hu} –¥–æ {max_hu} (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–µ–≥–∫–∏—Ö)")
                if not silent:
                    print(f"–ê–Ω–∞—Ç–æ–º–∏—á–µ—Å–∫–∞—è –æ–±–ª–∞—Å—Ç—å: {body_part or 'CHEST/LUNG (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)'}")
            else:
                # –î–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–µ–π (X-ray –∏ —Ç.–¥.) –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é
                if image_array.max() > image_array.min():
                    image_array = (image_array - image_array.min()) / (image_array.max() - image_array.min())
                    image_array = (image_array * 255).astype(np.uint8)
                else:
                    image_array = np.zeros_like(image_array, dtype=np.uint8)
                if not silent:
                    print(f"–ü—Ä–∏–º–µ–Ω–µ–Ω–∞ min-max –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç–∏: {modality}")
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ PIL Image
                image = Image.fromarray(image_array, mode='L')
                image_rgb = Image.new('RGB', image.size)
                image_rgb.paste(image)
                return image_rgb
            
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ CT windowing
            windowed_array = self.apply_ct_windowing(image_array, window_center, window_width)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ PIL Image
            image = Image.fromarray(windowed_array, mode='L')
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ RGB (MedGemma –æ–∂–∏–¥–∞–µ—Ç RGB)
            image_rgb = Image.new('RGB', image.size)
            image_rgb.paste(image)
            
            return image_rgb
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {dicom_path}: {e}")
            return None
    
    def analyze_image(self, image, file_path):
        """
        –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é MedGemma
        
        Args:
            image (PIL.Image): –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            file_path (str): –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –º–æ–¥–µ–ª–∏
            if "medgemma" in self.model_path.lower():
                # –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è MedGemma
                messages = [
                    {
                        "role": "system",
                        "content": [{"type": "text", "text": ANALYSIS_PROMPTS["system"]}]
                    },
                    {
                        "role": "user", 
                        "content": [
                            {"type": "text", "text": ANALYSIS_PROMPTS["single_image"]},
                            {"type": "image", "image": image}
                        ]
                    }
                ]
                
                # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç MedGemma
                try:
                    output = self.pipe(text=messages, max_new_tokens=GENERATION_PARAMS["single_image_tokens"])
                    analysis_text = output[0]["generated_text"][-1]["content"]
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ MedGemma: {e}")
                    # Fallback –¥–ª—è MedGemma
                    prompt = f"{ANALYSIS_PROMPTS['system']} {ANALYSIS_PROMPTS['single_image']}"
                    output = self.pipe(prompt, max_new_tokens=GENERATION_PARAMS["single_image_tokens"])
                    analysis_text = output[0]["generated_text"]
            else:
                # –û—à–∏–±–∫–∞: –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ç–æ–ª—å–∫–æ MedGemma –º–æ–¥–µ–ª—å
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è –º–æ–¥–µ–ª—å: {self.model_path}. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏ MedGemma.")
            
            return {
                'file_path': file_path,
                'analysis': analysis_text,
                'file_name': os.path.basename(file_path)
            }
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ {file_path}: {e}")
            return {
                'file_path': file_path,
                'analysis': f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}',
                'file_name': os.path.basename(file_path)
            }
    
    def analyze_all_images(self, images, file_paths):
        """
        –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å—Ä–∞–∑—É
        
        Args:
            images (list): –°–ø–∏—Å–æ–∫ PIL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            file_paths (list): –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º
            
        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–∞–∂ –∏–∑ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± - –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)
            # MedGemma –º–æ–∂–µ—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞ —Ä–∞–∑
            # –ü–æ—ç—Ç–æ–º—É –±—É–¥–µ–º –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—è –≤—Å–µ—Ö
            
            if not images:
                return {
                    'file_paths': file_paths,
                    'analysis': '–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞',
                    'total_files': 0
                }
            
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            main_image = images[0]
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è MedGemma (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –±–ª–æ–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏)
            messages = [
                {
                    "role": "system",
                    "content": [{"type": "text", "text": ANALYSIS_PROMPTS["series_system"]}]
                },
                {
                    "role": "user", 
                    "content": [
                        {"type": "text", "text": f"Analyze this chest CT image from a series of {len(images)} DICOM files. Focus on lung pathology and provide detailed assessment of this representative image with general recommendations for the entire series."},
                        {"type": "image", "image": main_image}
                    ]
                }
            ]
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç MedGemma
            output = self.pipe(text=messages, max_new_tokens=300)
            analysis_text = output[0]["generated_text"][-1]["content"]
            
            return {
                'file_paths': file_paths,
                'analysis': analysis_text,
                'total_files': len(images),
                'analyzed_image': os.path.basename(file_paths[0]) if file_paths else "unknown"
            }
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {e}")
            return {
                'file_paths': file_paths,
                'analysis': f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}',
                'total_files': len(images),
                'analyzed_image': "unknown"
            }
    
    def create_combined_analysis(self, analyses, file_paths):
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
        
        Args:
            analyses (list): –°–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–∏–∑–æ–≤ –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            file_paths (list): –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º
            
        Returns:
            dict: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∞–Ω–∞–ª–∏–∑—ã –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç
            combined_text = "\n\n".join([f"Analysis {i+1}: {analysis}" for i, analysis in enumerate(analyses)])
            
            # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è MedGemma –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            messages = [
                {
                    "role": "system",
                    "content": [{"type": "text", "text": ANALYSIS_PROMPTS["series_system"]}]
                },
                {
                    "role": "user", 
                    "content": [
                        {"type": "text", "text": ANALYSIS_PROMPTS["series_report"].format(count=len(analyses), analyses=combined_text)}
                    ]
                }
            ]
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç MedGemma
            output = self.pipe(text=messages, max_new_tokens=GENERATION_PARAMS["series_report_tokens"])
            combined_analysis = output[0]["generated_text"][-1]["content"]
            
            return {
                'file_paths': file_paths,
                'analysis': combined_analysis,
                'total_files': len(analyses),
                'individual_analyses': analyses
            }
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –æ–±—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑, –ø—Ä–æ—Å—Ç–æ –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—Å—Ç—ã
            combined_text = "\n\n".join([f"Analysis {i+1}: {analysis}" for i, analysis in enumerate(analyses)])
            return {
                'file_paths': file_paths,
                'analysis': f"Combined Analysis (Individual Reports):\n\n{combined_text}",
                'total_files': len(analyses),
                'individual_analyses': analyses
            }
    
    def analyze_batch(self, images, file_paths):
        """
        –ê–Ω–∞–ª–∏–∑ –±–∞—Ç—á–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        
        Args:
            images (list): –°–ø–∏—Å–æ–∫ PIL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            file_paths (list): –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–∏–∑–æ–≤
        """
        batch_analyses = []
        total_images = len(images)
        
        print(f"‚ö° –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {total_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –±–∞—Ç—á–∞–º–∏ –ø–æ {self.batch_size}...")
        
        total_processing_time = 0
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–∞—Ç—á–∞–º–∏
        for i in range(0, total_images, self.batch_size):
            batch_end = min(i + self.batch_size, total_images)
            current_batch_size = batch_end - i
            batch_num = (i // self.batch_size) + 1
            total_batches = (total_images + self.batch_size - 1) // self.batch_size
            
            print(f"üîÑ –ë–∞—Ç—á {batch_num}/{total_batches}: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {current_batch_size} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
            batch_start_time = time.time()
            
            batch_images = images[i:batch_end]
            batch_paths = file_paths[i:batch_end]
            
            for j, (image, file_path) in enumerate(zip(batch_images, batch_paths)):
                try:
                    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è MedGemma
                    messages = [
                        {
                            "role": "system",
                            "content": [{"type": "text", "text": ANALYSIS_PROMPTS["system"]}]
                        },
                        {
                            "role": "user", 
                            "content": [
                                {"type": "text", "text": ANALYSIS_PROMPTS["batch_analysis"]},
                                {"type": "image", "image": image}
                            ]
                        }
                    ]
                    
                    # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç MedGemma
                    output = self.pipe(text=messages, max_new_tokens=GENERATION_PARAMS["batch_tokens"])
                    analysis_text = output[0]["generated_text"][-1]["content"]
                    
                    batch_analyses.append({
                        'file_path': file_path,
                        'analysis': analysis_text,
                        'file_name': os.path.basename(file_path)
                    })
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ {os.path.basename(file_path)}: {e}")
                    continue
            
            batch_end_time = time.time()
            batch_duration = batch_end_time - batch_start_time
            total_processing_time += batch_duration
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏
            images_per_second = current_batch_size / batch_duration if batch_duration > 0 else 0
            
            print(f"‚úÖ –ë–∞—Ç—á {batch_num}/{total_batches} –∑–∞–≤–µ—Ä—à–µ–Ω: {current_batch_size} –∞–Ω–∞–ª–∏–∑–æ–≤ –∑–∞ {batch_duration:.1f}—Å ({images_per_second:.1f} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π/—Å–µ–∫)")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        avg_time_per_image = total_processing_time / total_images if total_images > 0 else 0
        total_images_per_second = total_images / total_processing_time if total_processing_time > 0 else 0
        
        print(f"üéâ –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(batch_analyses)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        print(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_processing_time:.1f} —Å–µ–∫—É–Ω–¥")
        print(f"üìà –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {total_images_per_second:.1f} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π/—Å–µ–∫ ({avg_time_per_image:.1f}—Å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–∏ GPU pipelines
        if self.device == "cuda":
            print("‚ÑπÔ∏è  –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –°–æ–æ–±—â–µ–Ω–∏–µ 'pipelines sequentially on GPU' –æ–∂–∏–¥–∞–µ–º–æ –ø—Ä–∏ –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ")
        
        return batch_analyses
    
    def analyze_images_efficiently(self, images, file_paths):
        """
        –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ GPU
        
        Args:
            images (list): –°–ø–∏—Å–æ–∫ PIL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            file_paths (list): –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–∏–∑–æ–≤
        """
        if not images:
            return []
        
        results = []
        total_images = len(images)
        
        print(f"üöÄ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –±–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ {total_images} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
        print(f"üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ GPU: {self.batch_size}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–∞—Ç—á–∞–º–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ GPU
        for i in range(0, total_images, self.batch_size):
            batch_end = min(i + self.batch_size, total_images)
            batch_images = images[i:batch_end]
            batch_paths = file_paths[i:batch_end]
            current_batch_size = len(batch_images)
            
            batch_num = (i // self.batch_size) + 1
            total_batches = (total_images + self.batch_size - 1) // self.batch_size
            
            print(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á {batch_num}/{total_batches} ({current_batch_size} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)...")
            
            try:
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –≤—Å–µ–≥–æ –±–∞—Ç—á–∞
                batch_messages = []
                for image in batch_images:
                    messages = [
                        {
                            "role": "system",
                            "content": [{"type": "text", "text": ANALYSIS_PROMPTS["system"]}]
                        },
                        {
                            "role": "user", 
                            "content": [
                                {"type": "text", "text": ANALYSIS_PROMPTS["batch_analysis"]},
                                {"type": "image", "image": image}
                            ]
                        }
                    ]
                    batch_messages.append(messages)
                
                # –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ pipeline
                batch_start_time = time.time()
                outputs = self.pipe(batch_messages, max_new_tokens=GENERATION_PARAMS["batch_tokens"])
                batch_duration = time.time() - batch_start_time
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                for j, (output, file_path) in enumerate(zip(outputs, batch_paths)):
                    try:
                        if isinstance(output, list) and len(output) > 0:
                            analysis_text = output[0]["generated_text"][-1]["content"]
                        else:
                            analysis_text = str(output)
                        
                        results.append({
                            'file_path': file_path,
                            'analysis': analysis_text,
                            'file_name': os.path.basename(file_path)
                        })
                    except Exception as e:
                        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è {os.path.basename(file_path)}: {e}")
                        results.append({
                            'file_path': file_path,
                            'analysis': f'–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {str(e)}',
                            'file_name': os.path.basename(file_path)
                        })
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞—Ç—á–∞
                images_per_second = current_batch_size / batch_duration if batch_duration > 0 else 0
                print(f"‚úÖ –ë–∞—Ç—á {batch_num}/{total_batches} –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {batch_duration:.1f}—Å ({images_per_second:.1f} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π/—Å–µ–∫)")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –±–∞—Ç—á–∞ {batch_num}: {e}")
                print("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –ø–æ—à—Ç—É—á–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è —ç—Ç–æ–≥–æ –±–∞—Ç—á–∞...")
                
                # Fallback –Ω–∞ –ø–æ—à—Ç—É—á–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ –±–∞—Ç—á–∞
                for image, file_path in zip(batch_images, batch_paths):
                    try:
                        result = self.analyze_image(image, file_path)
                        results.append(result)
                    except Exception as e2:
                        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ {os.path.basename(file_path)}: {e2}")
                        continue
        
        print(f"üéâ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(results)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        return results
    
    def analyze_images_with_dataset(self, images, file_paths):
        """
        –ü—Ä–æ—Å—Ç–∞—è –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –±–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–∂–Ω–æ—Å—Ç–µ–π
        
        Args:
            images (list): –°–ø–∏—Å–æ–∫ PIL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            file_paths (list): –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–∏–∑–æ–≤
        """
        print(f"üöÄ –ü—Ä–æ—Å—Ç–∞—è –±–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
        print(f"üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {self.batch_size}")
        if self.device == "cuda":
            print("‚ÑπÔ∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ 'pipelines sequentially on GPU' - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è MedGemma")
        
        results = []
        total_images = len(images)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ—Å—Ç—ã–º–∏ –±–∞—Ç—á–∞–º–∏
        for i in range(0, total_images, self.batch_size):
            batch_end = min(i + self.batch_size, total_images)
            batch_images = images[i:batch_end]
            batch_paths = file_paths[i:batch_end]
            current_batch_size = len(batch_images)
            
            batch_num = (i // self.batch_size) + 1
            total_batches = (total_images + self.batch_size - 1) // self.batch_size
            
            print(f"üîÑ –ë–∞—Ç—á {batch_num}/{total_batches}: {current_batch_size} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –±–∞—Ç—á–∞  
            batch_messages = []
            for image in batch_images:
                messages = [
                    {
                        "role": "system",
                        "content": [{"type": "text", "text": ANALYSIS_PROMPTS["system"]}]
                    },
                    {
                        "role": "user", 
                        "content": [
                            {"type": "text", "text": ANALYSIS_PROMPTS["batch_analysis"]},
                            {"type": "image", "image": image}
                        ]
                    }
                ]
                batch_messages.append(messages)
            
            try:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–µ—Å—å –±–∞—Ç—á –æ–¥–Ω–∏–º –≤—ã–∑–æ–≤–æ–º
                batch_start_time = time.time()
                outputs = self.pipe(batch_messages, max_new_tokens=GENERATION_PARAMS["batch_tokens"])
                batch_duration = time.time() - batch_start_time
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                for j, (output, file_path) in enumerate(zip(outputs, batch_paths)):
                    try:
                        if isinstance(output, list) and len(output) > 0:
                            analysis_text = output[0]["generated_text"][-1]["content"]
                        else:
                            analysis_text = str(output)
                        
                        results.append({
                            'file_path': file_path,
                            'analysis': analysis_text,
                            'file_name': os.path.basename(file_path)
                        })
                    except Exception as e:
                        results.append({
                            'file_path': file_path,
                            'analysis': f'–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}',
                            'file_name': os.path.basename(file_path)
                        })
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                images_per_second = current_batch_size / batch_duration if batch_duration > 0 else 0
                print(f"‚úÖ –ë–∞—Ç—á {batch_num}/{total_batches} –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {batch_duration:.1f}—Å ({images_per_second:.1f} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π/—Å–µ–∫)")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –±–∞—Ç—á–∞ {batch_num}: {e}")
                # Fallback –Ω–∞ –ø–æ—à—Ç—É—á–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–ª—è —ç—Ç–æ–≥–æ –±–∞—Ç—á–∞
                for image, file_path in zip(batch_images, batch_paths):
                    try:
                        result = self.analyze_image(image, file_path)
                        results.append(result)
                    except Exception:
                        continue
        
        print(f"üéâ –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! {len(results)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        return results
    
    def _fallback_sequential_analysis(self, images, file_paths):
        """
        Fallback –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ—à—Ç—É—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        
        Args:
            images (list): –°–ø–∏—Å–æ–∫ PIL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            file_paths (list): –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º
            
        Returns:
            list: –°–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–∏–∑–æ–≤
        """
        results = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
        for i, (image, file_path) in enumerate(tqdm(zip(images, file_paths), desc="–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π", unit="–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", total=len(images))):
            try:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–¥–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                result = self.analyze_image(image, file_path)
                results.append(result)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                if (i + 1) % self.progress_interval == 0:
                    print(f"üìà –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i + 1}/{len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ {os.path.basename(file_path)}: {e}")
                continue
        
        return results
    
    def analyze_directory(self, directory_path):
        """
        –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö DICOM —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        
        Args:
            directory_path (str): –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å DICOM —Ñ–∞–π–ª–∞–º–∏
        """
        if not os.path.exists(directory_path):
            print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {directory_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
            if self.telegram:
                self.telegram.send_status("error", f"Directory not found: {directory_path}")
            return
        
        print(f"\n–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º DICOM —Ñ–∞–π–ª—ã –≤: {directory_path}")
        
        # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –∞–Ω–∞–ª–∏–∑–∞
        if self.telegram:
            self.telegram.send_status("analysis_start", f"üìÅ Directory: `{directory_path}`\nüîß Device: {self.device.upper()}\nü™ü Window: WL={self.window_level}, WW={self.window_width}")
        
        # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö DICOM —Ñ–∞–π–ª–æ–≤
        dicom_files = []
        for root, dirs, files in os.walk(directory_path):
            for file in files:
                if file.lower().endswith(('.dcm', '.dicom')):
                    dicom_files.append(os.path.join(root, file))
        
        if not dicom_files:
            print(f"DICOM —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {directory_path}")
            return
        
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(dicom_files)} DICOM —Ñ–∞–π–ª–æ–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º debug —Ä–µ–∂–∏–º
        if DEBUG_MODE:
            # –ë–µ—Ä–µ–º –∫–∞–∂–¥—ã–π 5-–π —Ñ–∞–π–ª –¥–æ –∫–æ–Ω—Ü–∞
            debug_files = []
            for i in range(0, len(dicom_files), 5):  # –ö–∞–∂–¥—ã–π 5-–π —Ñ–∞–π–ª
                debug_files.append(dicom_files[i])
            dicom_files = debug_files
            print(f"üêõ DEBUG –†–ï–ñ–ò–ú: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π 5-–π —Ñ–∞–π–ª, –≤—Å–µ–≥–æ {len(dicom_files)} —Ñ–∞–π–ª–æ–≤")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º
        images = []
        valid_files = []
        
        print("–ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –≤—ã–≤–æ–¥–æ–º –¥–ª—è –ø–æ–∫–∞–∑–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        first_file_processed = False
        
        for dicom_file in tqdm(dicom_files, desc="–ó–∞–≥—Ä—É–∑–∫–∞ DICOM —Ñ–∞–π–ª–æ–≤", unit="—Ñ–∞–π–ª"):
            # –ü–µ—Ä–≤—ã–π —Ñ–∞–π–ª - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –æ—Å—Ç–∞–ª—å–Ω—ã–µ - —Ç–∏—Ö–æ
            silent = first_file_processed
            
            image = self.load_dicom_as_image(dicom_file, silent=silent)
            if image is not None:
                images.append(image)
                valid_files.append(dicom_file)
                
                # –ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–∏—Ö–æ
                if not first_file_processed:
                    first_file_processed = True
                    if len(dicom_files) > 1:
                        print(f"üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã. –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ {len(dicom_files)-1} —Ñ–∞–π–ª–æ–≤...")
        
        if not images:
            print("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è!")
            return
        
        print(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        
        # –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
        print("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
        print(f"üîß –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device.upper()}")
        
        # –ü—Ä–æ—Å—Ç–æ–π –≤—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if self.device == "cuda" and len(images) > 1:
            try:
                print("üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞—Ç—á–µ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É GPU...")
                all_analyses = self.analyze_images_with_dataset(images, valid_files)
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
                print("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –ø–æ—à—Ç—É—á–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")
                all_analyses = self._fallback_sequential_analysis(images, valid_files)
        else:
            # –î–ª—è CPU –∏–ª–∏ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—à—Ç—É—á–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            print("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—à—Ç—É—á–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")
            all_analyses = self._fallback_sequential_analysis(images, valid_files)
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—â–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
        if all_analyses:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑—ã –∏ –ø—É—Ç–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            analyses = [result['analysis'] for result in all_analyses]
            file_paths = [result['file_path'] for result in all_analyses]
            combined_result = self.create_combined_analysis(analyses, file_paths)
            self.results.append(combined_result)
            
            # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∞–Ω–∞–ª–∏–∑–∞
            if self.telegram:
                self.telegram.send_status("analysis_complete", f"üìä Processed: {len(all_analyses)} images\n‚è±Ô∏è Analysis completed successfully")
                
                # –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç—á–µ—Ç–∞ –≤ Telegram (–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º)
                report_text = f"**DICOM Analysis Report**\n\n"
                report_text += f"üìÅ **Directory:** `{directory_path}`\n"
                report_text += f"üìä **Files Processed:** {len(all_analyses)}\n"
                report_text += f"üîß **Device:** {self.device.upper()}\n"
                report_text += f"ü™ü **Window Settings:** WL={self.window_level}, WW={self.window_width}\n\n"
                report_text += f"**ANALYSIS RESULTS:**\n\n"
                report_text += combined_result['analysis']
                
                self.telegram.send_status("report", report_text)
        else:
            print("‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—â–µ–≥–æ –æ—Ç—á–µ—Ç–∞")
            if self.telegram:
                self.telegram.send_status("error", "No analysis results to create report")
    
    def analyze_single_file(self, file_path):
        """
        –ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ DICOM —Ñ–∞–π–ª–∞
        
        Args:
            file_path (str): –ü—É—Ç—å –∫ DICOM —Ñ–∞–π–ª—É
        """
        if not os.path.exists(file_path):
            print(f"–§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            return
        
        print(f"\n–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª: {file_path}")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞)
        image = self.load_dicom_as_image(file_path, silent=False)
        if image is None:
            return
        
        # –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        result = self.analyze_image(image, file_path)
        self.results.append(result)
        
        print(f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –¥–ª—è —Ñ–∞–π–ª–∞: {result['file_name']}")
    
    def print_results_table(self):
        """–í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –≤–∏–¥–µ –∫—Ä–∞—Å–∏–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã"""
        if not self.results:
            print("\n–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è!")
            return
        
        print("\n" + "="*100)
        print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê DICOM –§–ê–ô–õ–û–í")
        print(f"–ú–æ–¥–µ–ª—å: MedGemma-{self.model_name.upper()} ({self.model_path})")
        print("="*100)
        
        # –í—ã–≤–æ–¥ –æ–±—â–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        for idx, result in enumerate(self.results, 1):
            print(f"\nüìä –ê–ù–ê–õ–ò–ó –°–ï–†–ò–ò {idx}:")
            print("-" * 100)
            
            if 'total_files' in result:
                # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç - –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
                print(f"üìÅ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {result['total_files']}")
                if 'analyzed_image' in result:
                    print(f"üîç –ü—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {result['analyzed_image']}")
                print(f"üìÇ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
                for file_path in result['file_paths'][:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 —Ñ–∞–π–ª–æ–≤
                    print(f"   - {os.path.basename(file_path)}")
                if len(result['file_paths']) > 5:
                    print(f"   ... –∏ –µ—â–µ {len(result['file_paths']) - 5} —Ñ–∞–π–ª–æ–≤")
                print(f"\nüí¨ –û–ë–©–ò–ô –ê–ù–ê–õ–ò–ó –ü–û –í–°–ï–ú –§–ê–ô–õ–ê–ú:")
                print(f"{result['analysis']}")
            else:
                # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç - –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                print(f"üìÅ –§–∞–π–ª: {result['file_name']}")
                print(f"üìÇ –ü—É—Ç—å: {result['file_path']}")
                print(f"üí¨ –ê–Ω–∞–ª–∏–∑: {result['analysis']}")
            
            print("-" * 100)
        
        # –û–±—â–∏–π –æ—Ç—á–µ—Ç
        total_series = len(self.results)
        total_files = sum(result.get('total_files', 1) for result in self.results)
        print(f"\nüìà –û–ë–©–ò–ô –û–¢–ß–ï–¢:")
        print("-" * 50)
        print(f"   –í—Å–µ–≥–æ —Å–µ—Ä–∏–π –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {total_series}")
        print(f"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_files}")
        print(f"   –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        
        print("\n" + "="*100)

def show_help():
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø—Ä–∞–≤–∫—É –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é"""
    help_text = """
üî¨ DICOM –ê–ù–ê–õ–ò–ó–ê–¢–û–† –° MEDGEMMA - –°–ü–†–ê–í–ö–ê

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï:
    python dicom_analyzer.py [–û–ü–¶–ò–ò] <–ü–£–¢–¨_–ö_–ü–ê–ü–ö–ï_–ò–õ–ò_–§–ê–ô–õ–£>

–û–°–ù–û–í–ù–´–ï –ö–û–ú–ê–ù–î–´:
    /–ø—É—Ç—å/–∫/–ø–∞–ø–∫–µ/         –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö DICOM —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ
    /–ø—É—Ç—å/–∫/—Ñ–∞–π–ª—É.dcm      –ê–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ DICOM —Ñ–∞–π–ª–∞
    '/–ø—É—Ç—å/–∫/—Ñ–∞–π–ª–∞–º/*'     –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ –ø–æ glob-–ø–∞—Ç—Ç–µ—Ä–Ω—É
    --help, -h             –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç—É —Å–ø—Ä–∞–≤–∫—É

–û–ü–¶–ò–ò –ú–û–î–ï–õ–ò:
    --model=4b|27b         –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ MedGemma (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 4b)
    --prompt="—Ç–µ–∫—Å—Ç"       –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    --lang=–Ø–ó–´–ö            –Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞: en, ru (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: en)

–û–ü–¶–ò–ò CT WINDOWING:
    --wl=–ß–ò–°–õ–û             Window Level (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: -550)
    --ww=–ß–ò–°–õ–û             Window Width (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 1600)
    --window=WL,WW         –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å WL –∏ WW –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π
    --pneumonia-window=–¢–ò–ü –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –æ–∫–Ω–∞: lung_soft, infection, standard_lung

–û–ü–¶–ò–ò –û–ë–†–ê–ë–û–¢–ö–ò:
    --batch-size=–ß–ò–°–õ–û     –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è GPU (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 4)
    --debug                –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π 5-–π —Ñ–∞–π–ª (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)

–û–ü–¶–ò–ò TELEGRAM:
    --telegram-token=–¢–û–ö–ï–ù –¢–æ–∫–µ–Ω Telegram –±–æ—Ç–∞
    --telegram-chat=ID     Chat ID –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π

–ü–†–ò–ú–ï–†–´:
    # –ê–Ω–∞–ª–∏–∑ –ø–∞–ø–∫–∏ —Å —Ñ–∞–π–ª–∞–º–∏
    python dicom_analyzer.py /data/dicom_files/
    
    # –ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    python dicom_analyzer.py /data/scan.dcm
    
    # –ê–Ω–∞–ª–∏–∑ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ —Ñ–∞–π–ª–æ–≤ (glob-–ø–∞—Ç—Ç–µ—Ä–Ω—ã)
    python dicom_analyzer.py '/data/example/abnormal/1/IMG-000*'
    python dicom_analyzer.py '/data/scans/patient_*/slice_[0-9][0-9].dcm'
    python dicom_analyzer.py '/data/study/IMG-00[1-5]*.dcm'
    
    # –î–µ–±–∞–≥ —Ä–µ–∂–∏–º —Å –º–æ–¥–µ–ª—å—é 27B
    python dicom_analyzer.py --debug --model=27b /data/
    
    # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç —Å glob-–ø–∞—Ç—Ç–µ—Ä–Ω–æ–º
    python dicom_analyzer.py --prompt="–ù–∞–π–¥–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–Ω–µ–≤–º–æ–Ω–∏–∏" '/data/covid_cases/IMG-*.dcm'
    
    # –û—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
    python dicom_analyzer.py --lang=ru '/data/example/abnormal/1/IMG-000*'
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –¥–ª—è –∏–Ω—Ñ–µ–∫—Ü–∏–π
    python dicom_analyzer.py --pneumonia-window=infection '/data/pneumonia/IMG-*.dcm'
    
    # –ê–Ω–∞–ª–∏–∑ —Å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è–º–∏ –≤ Telegram
    python dicom_analyzer.py --telegram-token=YOUR_BOT_TOKEN --telegram-chat=YOUR_CHAT_ID '/data/scans/'

DOCKER –ü–†–ò–ú–ï–†–´:
    # –ê–Ω–∞–ª–∏–∑ –ø–∞–ø–∫–∏ —á–µ—Ä–µ–∑ Docker
    docker-compose run --rm dicom-analyzer /data
    
    # –° –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    docker-compose run --rm dicom-analyzer --model=27b --debug /data
"""
    print(help_text)

def expand_glob_pattern(pattern):
    """–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ glob-–ø–∞—Ç—Ç–µ—Ä–Ω–∞ –≤ —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –ø—É—Ç—å glob-—Å–∏–º–≤–æ–ª—ã
        if any(char in pattern for char in ['*', '?', '[', ']']):
            files = glob.glob(pattern)
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ DICOM —Ñ–∞–π–ª—ã
            dicom_files = []
            for file_path in files:
                if os.path.isfile(file_path):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∏–ª–∏ –ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–∫ DICOM
                    if (file_path.lower().endswith(('.dcm', '.dicom')) or 
                        not os.path.splitext(file_path)[1]):  # —Ñ–∞–π–ª—ã –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
                        dicom_files.append(file_path)
            
            dicom_files.sort()  # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞
            print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(dicom_files)} DICOM —Ñ–∞–π–ª–æ–≤ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É: {pattern}")
            return dicom_files
        else:
            # –û–±—ã—á–Ω—ã–π –ø—É—Ç—å –±–µ–∑ glob-—Å–∏–º–≤–æ–ª–æ–≤
            return [pattern] if os.path.exists(pattern) else []
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ '{pattern}': {e}")
        return []

def analyze_single_file(file_path, analyzer):
    """–ê–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ DICOM —Ñ–∞–π–ª–∞"""
    print(f"\nüìÅ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª: {file_path}")
    
    if not os.path.exists(file_path):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        return
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º DICOM —Ñ–∞–π–ª (–ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞)
        image = analyzer.load_dicom_as_image(file_path, silent=False)
        if image is None:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å DICOM —Ñ–∞–π–ª: {file_path}")
            return
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        result = analyzer.analyze_image(image, file_path)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        print(f"\nüîç –†–ï–ó–£–õ–¨–¢–ê–¢ –ê–ù–ê–õ–ò–ó–ê:")
        print(f"–§–∞–π–ª: {result['file_name']}")
        print(f"–ê–Ω–∞–ª–∏–∑: {result['analysis']}")
        print("="*60)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")

def analyze_file_list(file_list, analyzer):
    """–ê–Ω–∞–ª–∏–∑ —Å–ø–∏—Å–∫–∞ DICOM —Ñ–∞–π–ª–æ–≤ —Å –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
    if not file_list:
        print("‚ùå –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –ø—É—Å—Ç")
        if analyzer.telegram:
            analyzer.telegram.send_status("error", "File list is empty")
        return
    
    print(f"\nüìã –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(file_list)} —Ñ–∞–π–ª–æ–≤ –±–∞—Ç—á–∞–º–∏...")
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –∞–Ω–∞–ª–∏–∑–∞
    print(f"üî• DEBUG: analyzer.telegram={'–î–ê' if analyzer.telegram else '–ù–ï–¢'}")
    if analyzer.telegram:
        print("üî• –û–¢–ü–†–ê–í–õ–Ø–Æ –£–í–ï–î–û–ú–õ–ï–ù–ò–ï –û –ù–ê–ß–ê–õ–ï –ê–ù–ê–õ–ò–ó–ê –í TELEGRAM...")
        result = analyzer.telegram.send_status("analysis_start", f"üìã Files to process: {len(file_list)}\nüîß Device: {analyzer.device.upper()}\nü™ü Window: WL={analyzer.window_level}, WW={analyzer.window_width}")
        print(f"üî• –†–ï–ó–£–õ–¨–¢–ê–¢ –û–¢–ü–†–ê–í–ö–ò –ù–ê–ß–ê–õ–ê: {result}")
    else:
        print("üî• DEBUG: analyzer.telegram –ù–ï–¢ - —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è!")
    
    # –ï—Å–ª–∏ –æ–¥–∏–Ω —Ñ–∞–π–ª - –∏—Å–ø–æ–ª—å–∑—É–µ–º analyze_single_file
    if len(file_list) == 1:
        analyze_single_file(file_list[0], analyzer)
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –≤—ã–≤–æ–¥–æ–º
    print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DICOM —Ñ–∞–π–ª–æ–≤...")
    images_and_paths = []
    
    for file_path in tqdm(file_list, desc="–ó–∞–≥—Ä—É–∑–∫–∞ DICOM", leave=False):
        try:
            if not os.path.exists(file_path):
                continue
                
            # –ó–∞–≥—Ä—É–∂–∞–µ–º DICOM –±–µ–∑ –≤—ã–≤–æ–¥–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
            image = analyzer.load_dicom_as_image(file_path, silent=True)
            if image is not None:
                images_and_paths.append((image, file_path))
                
        except Exception:
            continue  # –¢–∏—Ö–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ñ–∞–π–ª—ã
    
    if not images_and_paths:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
        return
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(images_and_paths)} —Ñ–∞–π–ª–æ–≤")
    print("ü§ñ –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Å MedGemma...")
    print(f"üîß –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {analyzer.device.upper()}")
    
    # –í—ã–±–∏—Ä–∞–µ–º –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    try:
        images = [img for img, _ in images_and_paths]
        file_paths = [path for _, path in images_and_paths]
        
        if analyzer.device == "cuda" and len(images) > 1:
            try:
                print("üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–∞—Ç—á–µ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É GPU...")
                results = analyzer.analyze_images_with_dataset(images, file_paths)
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
                print("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –ø–æ—à—Ç—É—á–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")
                results = analyzer._fallback_sequential_analysis(images, file_paths)
        else:
            print("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—à—Ç—É—á–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É...")
            results = analyzer._fallback_sequential_analysis(images, file_paths)
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—â–∏–π –æ—Ç—á–µ—Ç
        print(f"üîç DEBUG: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results) if results else 0}")
        if results:
            print(f"üîç DEBUG: –¢–∏–ø –ø–µ—Ä–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {type(results[0])}")
            print(f"üîç DEBUG: –ö–ª—é—á–∏ –ø–µ—Ä–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {list(results[0].keys()) if isinstance(results[0], dict) else '–Ω–µ —Å–ª–æ–≤–∞—Ä—å'}")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑—ã –∏ –ø—É—Ç–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            analyses = [result['analysis'] for result in results]
            file_paths = [result['file_path'] for result in results]
            combined_report = analyzer.create_combined_analysis(analyses, file_paths)
            
            # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∞–Ω–∞–ª–∏–∑–∞
            if analyzer.telegram:
                print("üî• –û–¢–ü–†–ê–í–õ–Ø–Æ –£–í–ï–î–û–ú–õ–ï–ù–ò–ï –û –ó–ê–í–ï–†–®–ï–ù–ò–ò –í TELEGRAM...")
                result = analyzer.telegram.send_status("analysis_complete", f"üìä Processed: {len(results)} files\n‚è±Ô∏è Analysis completed successfully")
                print(f"üî• –†–ï–ó–£–õ–¨–¢–ê–¢ –û–¢–ü–†–ê–í–ö–ò –ó–ê–í–ï–†–®–ï–ù–ò–Ø: {result}")
                
                # –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç—á–µ—Ç–∞ –≤ Telegram (–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º)
                print("üî• –û–¢–ü–†–ê–í–õ–Ø–Æ –û–¢–ß–ï–¢ –í TELEGRAM...")
                report_text = f"**DICOM Analysis Report**\n\n"
                report_text += f"üìã **Files Processed:** {len(results)}\n"
                report_text += f"üîß **Device:** {analyzer.device.upper()}\n"
                report_text += f"ü™ü **Window Settings:** WL={analyzer.window_level}, WW={analyzer.window_width}\n\n"
                report_text += f"**ANALYSIS RESULTS:**\n\n"
                report_text += combined_report['analysis']
                
                result = analyzer.telegram.send_status("report", report_text)
                print(f"üî• –†–ï–ó–£–õ–¨–¢–ê–¢ –û–¢–ü–†–ê–í–ö–ò –û–¢–ß–ï–¢–ê: {result}")
            
            print(f"\nüìä –û–ë–©–ò–ô –û–¢–ß–ï–¢ –ü–û {len(results)} –§–ê–ô–õ–ê–ú:")
            print("="*80)
            print(combined_report['analysis'])
            print("="*80)
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª—ã")
            if analyzer.telegram:
                analyzer.telegram.send_status("error", "Failed to analyze files")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}")
        print("üîÑ –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞...")
        
        # Fallback - –ø–æ—à—Ç—É—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ –≤—ã–≤–æ–¥–∞
        results = []
        for image, file_path in tqdm(images_and_paths, desc="–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ (fallback)"):
            try:
                result = analyzer.analyze_image(image, file_path)
                results.append(result)
            except Exception:
                continue
        
        print(f"üîç DEBUG (fallback): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results) if results else 0}")
        if results:
            print(f"üîç DEBUG (fallback): –¢–∏–ø –ø–µ—Ä–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {type(results[0])}")
            print(f"üîç DEBUG (fallback): –ö–ª—é—á–∏ –ø–µ—Ä–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {list(results[0].keys()) if isinstance(results[0], dict) else '–Ω–µ —Å–ª–æ–≤–∞—Ä—å'}")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑—ã –∏ –ø—É—Ç–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            analyses = [result['analysis'] for result in results]
            file_paths = [result['file_path'] for result in results]
            combined_report = analyzer.create_combined_analysis(analyses, file_paths)
            
            # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∞–Ω–∞–ª–∏–∑–∞ (fallback)
            if analyzer.telegram:
                analyzer.telegram.send_status("analysis_complete", f"üìä Processed: {len(results)} files (fallback mode)\n‚è±Ô∏è Analysis completed successfully")
                
                # –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç—á–µ—Ç–∞ –≤ Telegram (–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º)
                report_text = f"**DICOM Analysis Report (Fallback)**\n\n"
                report_text += f"üìã **Files Processed:** {len(results)}\n"
                report_text += f"üîß **Device:** {analyzer.device.upper()}\n"
                report_text += f"ü™ü **Window Settings:** WL={analyzer.window_level}, WW={analyzer.window_width}\n\n"
                report_text += f"**ANALYSIS RESULTS:**\n\n"
                report_text += combined_report['analysis']
                
                analyzer.telegram.send_status("report", report_text)
            
            print(f"\nüìä –û–ë–©–ò–ô –û–¢–ß–ï–¢ –ü–û {len(results)} –§–ê–ô–õ–ê–ú:")
            print("="*80)
            print(combined_report['analysis'])
            print("="*80)
        else:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª—ã (fallback)")
            if analyzer.telegram:
                analyzer.telegram.send_status("error", "Failed to analyze files (fallback mode)")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üî¨ DICOM –ê–ù–ê–õ–ò–ó–ê–¢–û–† –° MEDGEMMA")
    print("="*60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø—Ä–∞–≤–∫—É
    if "--help" in sys.argv or "-h" in sys.argv:
        show_help()
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ debug –≤ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    global DEBUG_MODE
    if "--debug" in sys.argv:
        DEBUG_MODE = True
        sys.argv.remove("--debug")
        print("üêõ DEBUG –†–ï–ñ–ò–ú –í–ö–õ–Æ–ß–ï–ù - –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π 5-–π —Ñ–∞–π–ª –¥–æ –∫–æ–Ω—Ü–∞")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    model_name = DEFAULT_MODEL
    window_level = DEFAULT_WINDOW_LEVEL
    window_width = DEFAULT_WINDOW_WIDTH
    batch_size = None
    custom_prompt = None
    language = "en"
    telegram_token = None
    telegram_chat_id = None
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    args_to_remove = []
    
    for i, arg in enumerate(sys.argv):
        if arg.startswith("--model="):
            model_name = arg.split("=")[1]
            args_to_remove.append(arg)
        elif arg == "--model" and i + 1 < len(sys.argv):
            model_name = sys.argv[i + 1]
            args_to_remove.extend([arg, sys.argv[i + 1]])
        elif arg.startswith("--wl="):
            window_level = int(arg.split("=")[1])
            args_to_remove.append(arg)
        elif arg == "--wl" and i + 1 < len(sys.argv):
            window_level = int(sys.argv[i + 1])
            args_to_remove.extend([arg, sys.argv[i + 1]])
        elif arg.startswith("--ww="):
            window_width = int(arg.split("=")[1])
            args_to_remove.append(arg)
        elif arg == "--ww" and i + 1 < len(sys.argv):
            window_width = int(sys.argv[i + 1])
            args_to_remove.extend([arg, sys.argv[i + 1]])
        elif arg.startswith("--window="):
            # –§–æ—Ä–º–∞—Ç: --window=WL,WW –Ω–∞–ø—Ä–∏–º–µ—Ä --window=-550,1600
            wl_ww = arg.split("=")[1].split(",")
            if len(wl_ww) == 2:
                window_level = int(wl_ww[0])
                window_width = int(wl_ww[1])
            args_to_remove.append(arg)
        elif arg.startswith("--pneumonia-window="):
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –æ–∫–Ω–∞ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –ø–Ω–µ–≤–º–æ–Ω–∏–∏
            window_type = arg.split("=")[1]
            if window_type in PNEUMONIA_DETECTION_WINDOWS:
                window_level = PNEUMONIA_DETECTION_WINDOWS[window_type]["wl"]
                window_width = PNEUMONIA_DETECTION_WINDOWS[window_type]["ww"]
                print(f"üîç –í—ã–±—Ä–∞–Ω–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –¥–ª—è –ø–Ω–µ–≤–º–æ–Ω–∏–∏: {window_type}")
            args_to_remove.append(arg)
        elif arg.startswith("--batch-size="):
            # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            batch_size = int(arg.split("=")[1])
            args_to_remove.append(arg)
        elif arg == "--batch-size" and i + 1 < len(sys.argv):
            batch_size = int(sys.argv[i + 1])
            args_to_remove.extend([arg, sys.argv[i + 1]])
        elif arg.startswith("--prompt="):
            # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
            custom_prompt = arg.split("=", 1)[1].strip('"').strip("'")
            args_to_remove.append(arg)
        elif arg == "--prompt" and i + 1 < len(sys.argv):
            custom_prompt = sys.argv[i + 1].strip('"').strip("'")
            args_to_remove.extend([arg, sys.argv[i + 1]])
        elif arg.startswith("--lang="):
            # –Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞
            language = arg.split("=")[1].lower()
            args_to_remove.append(arg)
        elif arg == "--lang" and i + 1 < len(sys.argv):
            language = sys.argv[i + 1].lower()
            args_to_remove.extend([arg, sys.argv[i + 1]])
        elif arg.startswith("--telegram-token="):
            # –¢–æ–∫–µ–Ω Telegram –±–æ—Ç–∞
            telegram_token = arg.split("=", 1)[1]
            args_to_remove.append(arg)
        elif arg == "--telegram-token" and i + 1 < len(sys.argv):
            telegram_token = sys.argv[i + 1]
            args_to_remove.extend([arg, sys.argv[i + 1]])
        elif arg.startswith("--telegram-chat="):
            # Chat ID –¥–ª—è Telegram
            telegram_chat_id = arg.split("=", 1)[1]
            args_to_remove.append(arg)
        elif arg == "--telegram-chat" and i + 1 < len(sys.argv):
            telegram_chat_id = sys.argv[i + 1]
            args_to_remove.extend([arg, sys.argv[i + 1]])
    
    # –£–¥–∞–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    for arg in args_to_remove:
        if arg in sys.argv:
            sys.argv.remove(arg)
    
    print(f"ü§ñ –í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å: MedGemma-{model_name.upper()}")
    print(f"ü™ü –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–∫–Ω–∞: WL={window_level}, WW={window_width}")
    if batch_size:
        print(f"üì¶ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_size}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ Telegram notifier
    telegram_notifier = None
    print(f"üî• DEBUG: telegram_token={'–î–ê' if telegram_token else '–ù–ï–¢'}, telegram_chat_id={'–î–ê' if telegram_chat_id else '–ù–ï–¢'}")
    if telegram_token and telegram_chat_id:
        print("üî• DEBUG: –°–æ–∑–¥–∞—é TelegramNotifier...")
        telegram_notifier = TelegramNotifier(telegram_token, telegram_chat_id)
        print(f"üî• DEBUG: TelegramNotifier —Å–æ–∑–¥–∞–Ω, enabled={telegram_notifier.enabled}")
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–ø—É—Å–∫–µ (–±—É–¥–µ—Ç –¥–æ–ø–æ–ª–Ω–µ–Ω–æ –ø–æ–∑–∂–µ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø—É—Ç–∏)
    elif telegram_token or telegram_chat_id:
        print("‚ö†Ô∏è  –î–ª—è Telegram —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –Ω—É–∂–Ω—ã –æ–±–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞: --telegram-token –∏ --telegram-chat")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    analyzer = DICOMAnalyzer(model_name=model_name, window_level=window_level, window_width=window_width, batch_size=batch_size, telegram_notifier=telegram_notifier)
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —è–∑—ã–∫–æ–≤—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
    global DEFAULT_ANALYSIS_PROMPT, CURRENT_LANGUAGE
    if language in LANGUAGE_PROMPTS:
        DEFAULT_ANALYSIS_PROMPT = LANGUAGE_PROMPTS[language]
        CURRENT_LANGUAGE = language
        ANALYSIS_PROMPTS["universal"] = DEFAULT_ANALYSIS_PROMPT
        ANALYSIS_PROMPTS["single_image"] = DEFAULT_ANALYSIS_PROMPT
        ANALYSIS_PROMPTS["batch_analysis"] = DEFAULT_ANALYSIS_PROMPT
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞
        if language == "ru":
            ANALYSIS_PROMPTS["system"] = "–í—ã - —ç–∫—Å–ø–µ—Ä—Ç-–ø—É–ª—å–º–æ–Ω–æ–ª–æ–≥ –∏ —Ä–µ–Ω—Ç–≥–µ–Ω–æ–ª–æ–≥ –≥—Ä—É–¥–Ω–æ–π –∫–ª–µ—Ç–∫–∏ —Å –æ–±—à–∏—Ä–Ω—ã–º –æ–ø—ã—Ç–æ–º –≤—ã—è–≤–ª–µ–Ω–∏—è –ø–Ω–µ–≤–º–æ–Ω–∏–∏, COVID-19 –∏ –¥—Ä—É–≥–∏—Ö –∏–Ω—Ñ–µ–∫—Ü–∏–æ–Ω–Ω—ã—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π –ª–µ–≥–∫–∏—Ö."
            ANALYSIS_PROMPTS["series_system"] = "–í—ã - —ç–∫—Å–ø–µ—Ä—Ç-–ø—É–ª—å–º–æ–Ω–æ–ª–æ–≥ –∏ —Ä–µ–Ω—Ç–≥–µ–Ω–æ–ª–æ–≥ –≥—Ä—É–¥–Ω–æ–π –∫–ª–µ—Ç–∫–∏, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –≤—ã—è–≤–ª–µ–Ω–∏–∏ –ø–Ω–µ–≤–º–æ–Ω–∏–∏ –∏ –∏–Ω—Ñ–µ–∫—Ü–∏–æ–Ω–Ω—ã—Ö –∑–∞–±–æ–ª–µ–≤–∞–Ω–∏–π –ª–µ–≥–∫–∏—Ö."
            ANALYSIS_PROMPTS["series_report"] = "–ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ {count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ö–¢ –≥—Ä—É–¥–Ω–æ–π –∫–ª–µ—Ç–∫–∏ —Å–æ–∑–¥–∞–π—Ç–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø—É–ª—å–º–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ä–∞–¥–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç. –í–æ—Ç –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ –∞–Ω–∞–ª–∏–∑—ã:\n\n{analyses}\n\n–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É —Å –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–º–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏."
        else:
            # –î–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å (—É–∂–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º)
            ANALYSIS_PROMPTS["system"] = "You are an expert pulmonologist and chest radiologist with extensive experience in detecting pneumonia, COVID-19, and other infectious lung diseases."
            ANALYSIS_PROMPTS["series_system"] = "You are an expert pulmonologist and chest radiologist specializing in pneumonia detection and infectious lung disease."
            ANALYSIS_PROMPTS["series_report"] = "Based on analysis of {count} chest CT images, create a comprehensive pulmonary radiological report. Here are the individual analyses:\n\n{analyses}\n\nProvide a definitive assessment with clinical recommendations."
        
        lang_names = {"en": "English", "ru": "–†—É—Å—Å–∫–∏–π"}
        print(f"üåç –Ø–∑—ã–∫ –æ—Ç–≤–µ—Ç–∞: {lang_names.get(language, language.upper())}")
    else:
        print(f"‚ö†Ô∏è  –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —è–∑—ã–∫ '{language}'. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {list(LANGUAGE_PROMPTS.keys())}")
        print("üåç –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
        language = "en"
        DEFAULT_ANALYSIS_PROMPT = LANGUAGE_PROMPTS["en"]
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –ø—Ä–æ–º–ø—Ç—ã
        ANALYSIS_PROMPTS["universal"] = DEFAULT_ANALYSIS_PROMPT
        ANALYSIS_PROMPTS["single_image"] = DEFAULT_ANALYSIS_PROMPT
        ANALYSIS_PROMPTS["batch_analysis"] = DEFAULT_ANALYSIS_PROMPT
        ANALYSIS_PROMPTS["system"] = "You are an expert pulmonologist and chest radiologist with extensive experience in detecting pneumonia, COVID-19, and other infectious lung diseases."
        ANALYSIS_PROMPTS["series_system"] = "You are an expert pulmonologist and chest radiologist specializing in pneumonia detection and infectious lung disease."
        ANALYSIS_PROMPTS["series_report"] = "Based on analysis of {count} chest CT images, create a comprehensive pulmonary radiological report. Here are the individual analyses:\n\n{analyses}\n\nProvide a definitive assessment with clinical recommendations."
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ)
    if custom_prompt:
        DEFAULT_ANALYSIS_PROMPT = custom_prompt
        ANALYSIS_PROMPTS["universal"] = custom_prompt
        ANALYSIS_PROMPTS["single_image"] = custom_prompt
        ANALYSIS_PROMPTS["batch_analysis"] = custom_prompt
        print(f"üí¨ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç: {custom_prompt[:50]}...")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if len(sys.argv) > 1:
        # –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞, –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏–ª–∏ glob-–ø–∞—Ç—Ç–µ—Ä–Ω–∞ –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
        path_pattern = sys.argv[1]
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–ª–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–ø—É—Å–∫–µ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –¥–∞–Ω–Ω—ã—Ö
        print(f"üî• DEBUG: telegram_notifier={'–î–ê' if telegram_notifier else '–ù–ï–¢'}")
        if telegram_notifier:
            print("üî• DEBUG: –ì–æ—Ç–æ–≤–ª—é —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–ø—É—Å–∫–µ...")
            start_details = f"ü§ñ Model: MedGemma-{model_name.upper()}\n"
            start_details += f"üîß Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\n"
            start_details += f"ü™ü Window: WL={window_level}, WW={window_width}\n"
            start_details += f"üìÅ Data: `{path_pattern}`\n"
            start_details += f"üêõ Debug Mode: {'ON' if DEBUG_MODE else 'OFF'}\n"
            if custom_prompt:
                start_details += f"üí¨ Custom Prompt: '{custom_prompt[:40]}...'\n"
            if batch_size:
                start_details += f"üì¶ Batch Size: {batch_size}\n"
            start_details += f"üåç Language: {language.upper()}"
            print("üî• –û–¢–ü–†–ê–í–õ–Ø–Æ –£–í–ï–î–û–ú–õ–ï–ù–ò–ï –û –ó–ê–ü–£–°–ö–ï –í TELEGRAM...")
            result = telegram_notifier.send_status("start", start_details)
            print(f"üî• –†–ï–ó–£–õ–¨–¢–ê–¢ –û–¢–ü–†–ê–í–ö–ò: {result}")
        else:
            print("üî• DEBUG: telegram_notifier –ù–ï–¢ - —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è!")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ glob-–ø–∞—Ç—Ç–µ—Ä–Ω–æ–º
        if any(char in path_pattern for char in ['*', '?', '[', ']']):
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∫ glob-–ø–∞—Ç—Ç–µ—Ä–Ω
            file_list = expand_glob_pattern(path_pattern)
            if file_list:
                analyze_file_list(file_list, analyzer)
            else:
                print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É: {path_pattern}")
                return
        elif os.path.isfile(path_pattern):
            # –ê–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            analyze_single_file(path_pattern, analyzer)
        elif os.path.isdir(path_pattern):
            # –ê–Ω–∞–ª–∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
            analyzer.analyze_directory(path_pattern)
        else:
            print(f"‚ùå –ü—É—Ç—å –∏–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω '{path_pattern}' –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            print("üí° –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:")
            print("   python dicom_analyzer.py /data/scan.dcm")
            print("   python dicom_analyzer.py /data/scans/")
            print("   python dicom_analyzer.py '/data/example/abnormal/1/IMG-000*'")
            return
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Ç—å –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π DICOM_FOLDER_PATH
        print(f"\n–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Ç—å –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫: {DICOM_FOLDER_PATH}")
        if DEBUG_MODE:
            print(f"üêõ Debug —Ä–µ–∂–∏–º: –±—É–¥–µ–º –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π 5-–π —Ñ–∞–π–ª –¥–æ –∫–æ–Ω—Ü–∞")
        
        if os.path.exists(DICOM_FOLDER_PATH):
            analyzer.analyze_directory(DICOM_FOLDER_PATH)
        else:
            print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {DICOM_FOLDER_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
            print("–ò–∑–º–µ–Ω–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é DICOM_FOLDER_PATH –≤ –Ω–∞—á–∞–ª–µ —Å–∫—Ä–∏–ø—Ç–∞ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å.")
            return
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    analyzer.print_results_table()
    
    print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")

if __name__ == "__main__":
    main()
