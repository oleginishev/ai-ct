#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ MedGemma –≤ Docker
"""

import os
import torch
from transformers import AutoProcessor, AutoModelForImageTextToText

MODEL_PATH = "/app/models/medgemma_4b"

def main():
    """–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞"""
    print('üè• MedGemma 4B - –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞')
    print('=' * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª—å
    if not os.path.exists(MODEL_PATH):
        print(f'‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ {MODEL_PATH}')
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º GPU
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f'üñ•Ô∏è  –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}')
    
    if device == "cuda":
        print(f'‚úÖ GPU: {torch.cuda.get_device_name(0)}')
        print(f'üíæ –ü–∞–º—è—Ç—å: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        print('üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å...')
        processor = AutoProcessor.from_pretrained(MODEL_PATH)
        model = AutoModelForImageTextToText.from_pretrained(
            MODEL_PATH,
            dtype=torch.float16,
            device_map="auto" if device == "cuda" else None,
            low_cpu_mem_usage=True,
            trust_remote_code=True
        )
        
        if device == "cpu":
            model = model.to(device)
        
        print('‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!')
        
        # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç
        print('\nüß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é...')
        messages = [
            {
                "role": "user",
                "content": [{"type": "text", "text": "Hello! How are you?"}]
            }
        ]
        
        inputs = processor.apply_chat_template(
            messages, add_generation_prompt=True, tokenize=True,
            return_dict=True, return_tensors="pt"
        )
        
        if device == "cuda":
            inputs = {k: v.to(device) for k, v in inputs.items()}
        
        input_len = inputs["input_ids"].shape[-1]
        print(f'üìè –î–ª–∏–Ω–∞ –≤—Ö–æ–¥–∞: {input_len} —Ç–æ–∫–µ–Ω–æ–≤')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
        input_tokens = inputs["input_ids"][0].tolist()
        print(f'üîç –í—Ö–æ–¥–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã: {input_tokens}')
        print(f'üîç –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç: "{processor.decode(input_tokens, skip_special_tokens=False)}"')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
        print(f'üîç EOS token: {processor.tokenizer.eos_token_id}')
        print(f'üîç PAD token: {processor.tokenizer.pad_token_id}')
        
        with torch.inference_mode():
            generation = model.generate(
                **inputs,
                max_new_tokens=50,
                do_sample=True,
                temperature=0.7,
                top_p=0.9,
                pad_token_id=processor.tokenizer.pad_token_id,
                eos_token_id=processor.tokenizer.eos_token_id,
                repetition_penalty=1.1
            )
            generation = generation[0][input_len:]
        
        print(f'üìè –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {len(generation)} —Ç–æ–∫–µ–Ω–æ–≤')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è
        print(f'üîç –ü–µ—Ä–≤—ã–µ 10 —Ç–æ–∫–µ–Ω–æ–≤: {generation[:10].tolist()}')
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –±–µ–∑ –ø—Ä–æ–ø—É—Å–∫–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
        result_raw = processor.decode(generation, skip_special_tokens=False)
        print(f'üìù –°—ã—Ä–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—Å —Ç–æ–∫–µ–Ω–∞–º–∏): "{result_raw}"')
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Å –ø—Ä–æ–ø—É—Å–∫–æ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
        result = processor.decode(generation, skip_special_tokens=True)
        print(f'üìù –û—á–∏—â–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: "{result}"')
        
        # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—É—Å—Ç–æ–π, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π —Å–ø–æ—Å–æ–±
        if not result.strip():
            result = processor.tokenizer.decode(generation, skip_special_tokens=True)
            print(f'üìù –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: "{result}"')
        
        print(f'\nüìã –†–ï–ó–£–õ–¨–¢–ê–¢:')
        print('=' * 40)
        print(result)
        print('=' * 40)
        
        print('\nüéâ MedGemma —Ä–∞–±–æ—Ç–∞–µ—Ç!')
        
    except Exception as e:
        print(f'‚ùå –û—à–∏–±–∫–∞: {e}')
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
