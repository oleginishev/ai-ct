#!/usr/bin/env python3
"""
MedGemma –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è MacBook Air M3
"""

import os
import torch
from transformers import AutoProcessor, AutoModelForImageTextToText
from PIL import Image
import time

MODEL_PATH = "./models/medgemma_4b"

def load_model_m3():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–ª—è M3"""
    print('üçé –ó–∞–≥—Ä—É–∂–∞–µ–º MedGemma –¥–ª—è MacBook Air M3...')
    
    try:
        # –î–ª—è M3 –∏—Å–ø–æ–ª—å–∑—É–µ–º MPS (Metal Performance Shaders)
        if torch.backends.mps.is_available():
            device = "mps"
            print('‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º MPS (Metal) —É—Å–∫–æ—Ä–µ–Ω–∏–µ')
        else:
            device = "cpu"
            print('‚ö†Ô∏è  MPS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º CPU')
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è M3
        model = AutoModelForImageTextToText.from_pretrained(
            MODEL_PATH,
            torch_dtype=torch.float16,  # float16 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
            device_map=None,  # –†—É—á–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ–º
            low_cpu_mem_usage=True,
            trust_remote_code=True
        )
        
        processor = AutoProcessor.from_pretrained(MODEL_PATH)
        
        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        model = model.to(device)
        
        print(f'‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {device}')
        return model, processor, device
        
    except Exception as e:
        print(f'‚ùå –û—à–∏–±–∫–∞: {e}')
        return None, None, None

def quick_analyze_m3(model, processor, device, image_path=None):
    """–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è M3"""
    print('\n‚ö° –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ (M3 –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)...')
    
    start_time = time.time()
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        if image_path and os.path.exists(image_path):
            image = Image.open(image_path).convert('RGB')
            # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
            image = image.resize((512, 512))
            print(f'üìÅ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}')
        else:
            # –°–æ–∑–¥–∞–µ–º –º–∞–ª–µ–Ω—å–∫–æ–µ —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = Image.new('RGB', (256, 256), color='white')
            print('üì∑ –¢–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (256x256)')
        
        # –û—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–º–ø—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "–ö—Ä–∞—Ç–∫–æ –æ–ø–∏—à–∏—Ç–µ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."},
                    {"type": "image", "image": image}
                ]
            }
        ]
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞
        inputs = processor.apply_chat_template(
            messages, 
            add_generation_prompt=True, 
            tokenize=True,
            return_dict=True, 
            return_tensors="pt"
        )
        
        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        inputs = {k: v.to(device) for k, v in inputs.items()}
        
        input_len = inputs["input_ids"].shape[-1]
        
        # –û—á–µ–Ω—å –±—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        with torch.inference_mode():
            generation = model.generate(
                **inputs,
                max_new_tokens=30,  # –û—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç
                do_sample=False,
                pad_token_id=processor.tokenizer.eos_token_id,
                use_cache=True,
                temperature=0.1
            )
            generation = generation[0][input_len:]
        
        result = processor.decode(generation, skip_special_tokens=True)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        print(f'\n‚ö° –†–ï–ó–£–õ–¨–¢–ê–¢ (–∑–∞ {processing_time:.1f} —Å–µ–∫):')
        print('=' * 50)
        print(result)
        print('=' * 50)
        
        return result, processing_time
        
    except Exception as e:
        print(f'‚ùå –û—à–∏–±–∫–∞: {e}')
        return None, 0

def text_only_qa_m3(model, processor, device, question):
    """–¢–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã (–±—ã—Å—Ç—Ä–µ–µ)"""
    print(f'\n‚ùì –¢–µ–∫—Å—Ç–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å: {question}')
    
    start_time = time.time()
    
    try:
        # –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–º–ø—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º
        prompt = f"–û—Ç–≤–µ—Ç—å—Ç–µ –∫—Ä–∞—Ç–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ: {question}"
        
        inputs = processor.tokenizer(prompt, return_tensors="pt").to(device)
        
        with torch.inference_mode():
            generation = model.generate(
                **inputs,
                max_new_tokens=50,
                do_sample=False,
                pad_token_id=processor.tokenizer.eos_token_id,
                use_cache=True
            )
            generation = generation[0][inputs["input_ids"].shape[-1]:]
        
        result = processor.tokenizer.decode(generation, skip_special_tokens=True)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        print(f'\n‚ö° –û–¢–í–ï–¢ (–∑–∞ {processing_time:.1f} —Å–µ–∫):')
        print('=' * 50)
        print(result)
        print('=' * 50)
        
        return result, processing_time
        
    except Exception as e:
        print(f'‚ùå –û—à–∏–±–∫–∞: {e}')
        return None, 0

def benchmark_m3():
    """–ë–µ–Ω—á–º–∞—Ä–∫ –¥–ª—è M3"""
    print('üèÅ –ë–µ–Ω—á–º–∞—Ä–∫ MedGemma –Ω–∞ MacBook Air M3...')
    
    model, processor, device = load_model_m3()
    if model is None:
        return
    
    print(f'\nüìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:')
    print(f'   –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}')
    print(f'   –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö: {model.dtype}')
    print(f'   MPS –¥–æ—Å—Ç—É–ø–µ–Ω: {torch.backends.mps.is_available()}')
    
    # –¢–µ—Å—Ç 1: –¢–µ–∫—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã (–±—ã—Å—Ç—Ä–µ–µ)
    print('\nüîÑ –¢–µ—Å—Ç 1: –¢–µ–∫—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã...')
    times_text = []
    questions = [
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –ø–Ω–µ–≤–º–æ–Ω–∏—è?",
        "–°–∏–º–ø—Ç–æ–º—ã –≥—Ä–∏–ø–ø–∞?",
        "–ö–∞–∫ –ª–µ—á–∏—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É?"
    ]
    
    for q in questions:
        result, time_taken = text_only_qa_m3(model, processor, device, q)
        if time_taken > 0:
            times_text.append(time_taken)
    
    # –¢–µ—Å—Ç 2: –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–º–µ–¥–ª–µ–Ω–Ω–µ–µ)
    print('\nüîÑ –¢–µ—Å—Ç 2: –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...')
    result, time_image = quick_analyze_m3(model, processor, device)
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f'\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –î–õ–Ø M3:')
    if times_text:
        avg_text = sum(times_text) / len(times_text)
        print(f'   –¢–µ–∫—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã: {avg_text:.1f} —Å–µ–∫')
    print(f'   –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {time_image:.1f} —Å–µ–∫')
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print(f'\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø M3:')
    if time_image > 60:
        print('   ‚ö†Ô∏è  –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω—ã–π')
        print('   üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã')
    elif time_image > 30:
        print('   ‚ö†Ô∏è  –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –º–µ–¥–ª–µ–Ω–Ω—ã–π')
        print('   üí° –£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π')
    else:
        print('   ‚úÖ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–∏–µ–º–ª–µ–º–∞—è')

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print('üçé MedGemma 4B - MacBook Air M3')
    print('=' * 50)
    
    if not os.path.exists(MODEL_PATH):
        print(f'‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ {MODEL_PATH}')
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º MPS
    if torch.backends.mps.is_available():
        print('‚úÖ MPS (Metal) —É—Å–∫–æ—Ä–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω–æ')
    else:
        print('‚ö†Ô∏è  MPS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –±—É–¥–µ—Ç –º–µ–¥–ª–µ–Ω–Ω–æ')
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–µ–Ω—á–º–∞—Ä–∫
    benchmark_m3()
    
    print('\nüéØ –°–û–í–ï–¢–´ –î–õ–Ø M3:')
    print('   1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã')
    print('   2. –£–º–µ–Ω—å—à–∏—Ç–µ —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–æ 256x256')
    print('   3. max_new_tokens = 30-50 –º–∞–∫—Å–∏–º—É–º')
    print('   4. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –±–æ–ª–µ–µ –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å')

if __name__ == "__main__":
    main()
