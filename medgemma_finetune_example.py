#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ—Ä fine-tuning MedGemma 4B –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –∑–∞–¥–∞—á
"""

import torch
from transformers import (
    AutoProcessor, 
    AutoModelForImageTextToText,
    TrainingArguments,
    Trainer,
    DataCollatorForLanguageModeling
)
from datasets import Dataset
import json

def prepare_training_data():
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    print('üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è fine-tuning...')
    
    # –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ)
    training_data = [
        {
            "image": "path/to/chest_xray_1.jpg",
            "text": "Normal chest X-ray with clear lung fields and normal cardiac silhouette.",
            "label": "normal"
        },
        {
            "image": "path/to/chest_xray_2.jpg", 
            "text": "Chest X-ray shows bilateral lower lobe consolidation consistent with pneumonia.",
            "label": "pneumonia"
        },
        {
            "image": "path/to/chest_xray_3.jpg",
            "text": "Chest X-ray demonstrates left upper lobe opacity concerning for tuberculosis.",
            "label": "tuberculosis"
        }
    ]
    
    return training_data

def create_dataset(training_data):
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    print('üóÇÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞...')
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è Hugging Face
    dataset_dict = {
        "text": [item["text"] for item in training_data],
        "label": [item["label"] for item in training_data]
    }
    
    dataset = Dataset.from_dict(dataset_dict)
    return dataset

def setup_model_and_processor():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞"""
    print('üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞...')
    
    model_id = "google/medgemma-4b-it"
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    processor = AutoProcessor.from_pretrained(model_id)
    model = AutoModelForImageTextToText.from_pretrained(
        model_id,
        torch_dtype=torch.bfloat16,
        device_map="auto"
    )
    
    return model, processor

def fine_tune_model(model, processor, dataset):
    """Fine-tuning –º–æ–¥–µ–ª–∏"""
    print('üéØ –ù–∞—á–∏–Ω–∞–µ–º fine-tuning...')
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è
    training_args = TrainingArguments(
        output_dir="./medgemma-finetuned",
        num_train_epochs=3,
        per_device_train_batch_size=1,  # –ú–∞–ª—ã–π batch size –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        gradient_accumulation_steps=4,
        warmup_steps=100,
        learning_rate=5e-5,
        logging_steps=10,
        save_steps=500,
        evaluation_strategy="steps",
        eval_steps=500,
        save_total_limit=2,
        remove_unused_columns=False,
        push_to_hub=False,
        report_to="none"
    )
    
    # Data collator
    data_collator = DataCollatorForLanguageModeling(
        tokenizer=processor.tokenizer,
        mlm=False
    )
    
    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=dataset,
        data_collator=data_collator,
    )
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
    print('üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...')
    trainer.train()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    print('üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º fine-tuned –º–æ–¥–µ–ª—å...')
    trainer.save_model()
    processor.save_pretrained("./medgemma-finetuned")
    
    return trainer

def evaluate_model(model, processor, test_data):
    """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏"""
    print('üìä –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏...')
    
    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∫–æ–¥ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏
    # –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    
    pass

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è fine-tuning"""
    print('üéì MedGemma 4B - Fine-tuning Example')
    print('=' * 50)
    
    print('‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: Fine-tuning —Ç—Ä–µ–±—É–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤!')
    print('üíª –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è: GPU —Å –º–∏–Ω–∏–º—É–º 16GB VRAM')
    print('‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU
    if not torch.cuda.is_available():
        print('‚ùå CUDA –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞! Fine-tuning –º–æ–∂–µ—Ç –±—ã—Ç—å –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω—ã–º.')
        response = input('–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/n): ')
        if response.lower() != 'y':
            return
    
    try:
        # 1. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        training_data = prepare_training_data()
        
        # 2. –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        dataset = create_dataset(training_data)
        
        # 3. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
        model, processor = setup_model_and_processor()
        
        # 4. Fine-tuning
        trainer = fine_tune_model(model, processor, dataset)
        
        print('‚úÖ Fine-tuning –∑–∞–≤–µ—Ä—à–µ–Ω!')
        print('üìÅ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: ./medgemma-finetuned')
        
    except Exception as e:
        print(f'‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ fine-tuning: {e}')
        print('üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É –≤–∞—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ—Å—É—Ä—Å–æ–≤ –∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')

if __name__ == "__main__":
    main()
